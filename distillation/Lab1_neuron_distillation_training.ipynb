{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Neuron Distillation Training\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you will learn how to train a smaller \"student\" model using knowledge distillation on AWS Neuron hardware. This lab builds directly on Lab 0, where you generated teacher model logits from the Qwen3-30B-A3B model.\n",
    "\n",
    "Knowledge distillation allows you to compress a large, high-performance model into a smaller, more efficient model while retaining much of the original model's capabilities. The student model learns not just from the hard labels (POSITIVE, NEGATIVE, NEUTRAL), but from the full probability distributions (soft labels) produced by the teacher model.\n",
    "\n",
    "**Why Knowledge Distillation?**\n",
    "- **Cost Reduction**: Smaller models require fewer compute resources and lower inference costs\n",
    "- **Faster Inference**: Reduced model size means faster response times\n",
    "- **Better Generalization**: Learning from soft labels often produces models that generalize better than training on hard labels alone\n",
    "- **Deployment Flexibility**: Smaller models can be deployed on edge devices or in resource-constrained environments\n",
    "\n",
    "**Training Approach:**\n",
    "\n",
    "You will use a custom `KnowledgeDistillationTrainer` that combines two loss functions:\n",
    "1. **Hard Loss**: Standard cross-entropy loss with true labels (teaches the model the correct answers)\n",
    "2. **Soft Loss**: KL divergence between teacher and student logits (teaches the model the teacher's reasoning)\n",
    "\n",
    "The combined loss is: `total_loss = α × soft_loss + (1 - α) × hard_loss`\n",
    "\n",
    "Where α (alpha) controls the balance between learning from the teacher vs. learning from the labels.\n",
    "\n",
    "**Student Model:**\n",
    "\n",
    "You'll train [Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B), a 600 million parameter model - 50x smaller than the 30B teacher model!\n",
    "\n",
    "**Prerequisites:**\n",
    "- Completed Lab 0 with teacher logits saved to `data/output.json`\n",
    "- AWS Trainium based EC2 instance\n",
    "- AWS Neuron SDK installed\n",
    "- Sufficient disk space for model compilation and checkpoints (~30GB recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the student model weights\n",
    "\n",
    "First, download the student model weights from HuggingFace, using the HuggingFace CLI. The model detail page can be found here: [Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: neuronx-distributed in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (0.15.22404+1f27bddf)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: optimum-neuron[training] in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: torch-neuronx in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-distributed) (2.8.0.2.10.13553+1e4dd6ca)\n",
      "Requirement already satisfied: torch-xla in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-distributed) (2.8.1)\n",
      "Requirement already satisfied: safetensors in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-distributed) (0.6.2)\n",
      "Requirement already satisfied: tenacity in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-distributed) (9.1.2)\n",
      "Requirement already satisfied: setuptools>=70.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-distributed) (80.9.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: transformers~=4.55.4 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from optimum-neuron[training]) (4.55.4)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from optimum-neuron[training]) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from optimum-neuron[training]) (1.24.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from optimum-neuron[training]) (3.20.3)\n",
      "Requirement already satisfied: trl==0.11.4 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from optimum-neuron[training]) (0.11.4)\n",
      "Requirement already satisfied: peft==0.17.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from optimum-neuron[training]) (0.17.0)\n",
      "Requirement already satisfied: evaluate==0.4.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from optimum-neuron[training]) (0.4.3)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[training]) (7.1.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[training]) (2.8.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from trl==0.11.4->optimum-neuron[training]) (0.9.35)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from transformers~=4.55.4->optimum-neuron[training]) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from transformers~=4.55.4->optimum-neuron[training]) (0.21.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (1.3.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->optimum-neuron[training]) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->optimum-neuron[training]) (14.2.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->optimum-neuron[training]) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->optimum-neuron[training]) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->optimum-neuron[training]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->optimum-neuron[training]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->optimum-neuron[training]) (0.1.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[training]) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: libneuronxla<2.3,>=2.2 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch-neuronx->neuronx-distributed) (2.2.12677.0+470fa032)\n",
      "Requirement already satisfied: neuronx-cc~=2.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (2.21.18209.0+043b1bf7)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (1.40.60)\n",
      "Requirement already satisfied: botocore in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (1.40.60)\n",
      "Requirement already satisfied: scipy<=1.12.0,>=1.10.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (1.12.0)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (3.1.2)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (0.4.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (0.5.3)\n",
      "Requirement already satisfied: islpy~=2023.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (2023.2.5)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata~=2.10 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from torch-xla->neuronx-distributed) (2.3.1)\n",
      "Requirement already satisfied: lockfile>=0.10 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from python-daemon>=2.2.4->neuronx-cc~=2.0->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (0.12.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from boto3->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages (from boto3->libneuronxla<2.3,>=2.2->torch-neuronx->neuronx-distributed) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neuronx-distributed datasets optimum-neuron[training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|████████████████████| 10/10 [00:00<00:00, 146653.99it/s]\n",
      "/home/ubuntu/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/c1899de289a04d12100db370d81485cdf75e47ca\n"
     ]
    }
   ],
   "source": [
    "!hf download Qwen/Qwen3-0.6B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Configure environment variables to optimize Neuron compilation and runtime performance for distributed training.\n",
    "\n",
    "**Environment Variables Explained:**\n",
    "\n",
    "- **NEURON_CC_FLAGS**: Compiler flags for the Neuron compiler\n",
    "  - `--model-type transformer`: Optimizes compilation for transformer architectures\n",
    "  - `--retry_failed_compilation`: Automatically retry if compilation fails (improves reliability)\n",
    "\n",
    "- **NEURON_FUSE_SOFTMAX**: Enable softmax fusion optimization (combines operations for better performance)\n",
    "\n",
    "- **NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS**: Maximum number of concurrent inference requests (3 provides good throughput/latency balance)\n",
    "\n",
    "- **MALLOC_ARENA_MAX**: Limits memory arenas to reduce memory fragmentation during training (important for long-running jobs)\n",
    "\n",
    "- **WORLD_SIZE**: Total number of processes for distributed training. Set to 8 to match the number of NeuronCores we'll use (2 processes × 4 cores each = 8 total)\n",
    "\n",
    "These settings are critical for stable, efficient training on Neuron hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from src.util import prettyprint_python\n",
    "\n",
    "# Set Neuron compilation flags\n",
    "os.environ['NEURON_CC_FLAGS'] = \"--model-type transformer --retry_failed_compilation\"\n",
    "os.environ['NEURON_FUSE_SOFTMAX'] = \"1\"\n",
    "os.environ['NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS'] = \"3\"\n",
    "os.environ['MALLOC_ARENA_MAX'] = \"64\"\n",
    "os.environ['WORLD_SIZE'] = \"8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Define the hyperparameters and settings for the distillation training job.\n",
    "\n",
    "**Training Parameters:**\n",
    "\n",
    "- **PROCESSES_PER_NODE**: Number of training processes to run in parallel (2 processes for distributed training)\n",
    "  - Each process will use TP_DEGREE NeuronCores\n",
    "  - Total NeuronCores used = PROCESSES_PER_NODE × TP_DEGREE = 2 × 2 = 4\n",
    "\n",
    "- **NUM_EPOCHS**: Number of complete passes through the training dataset (3 epochs)\n",
    "  - More epochs = more training, but risk of overfitting on small datasets\n",
    "\n",
    "- **TP_DEGREE**: Tensor parallelism degree (2 NeuronCores per process)\n",
    "  - Distributes model layers across multiple cores for memory efficiency\n",
    "  - For a 0.6B model, TP=2 is sufficient\n",
    "\n",
    "- **BS**: Batch size per device (1 sample at a time)\n",
    "  - Small batch size for memory efficiency during compilation\n",
    "  - Effective batch size = BS × GRADIENT_ACCUMULATION_STEPS = 1 × 16 = 16\n",
    "\n",
    "- **GRADIENT_ACCUMULATION_STEPS**: Number of steps to accumulate gradients before updating weights (16)\n",
    "  - Simulates larger batch sizes without increasing memory usage\n",
    "  - Provides more stable gradient estimates\n",
    "\n",
    "- **LOGGING_STEPS**: Log training metrics every N steps (1 = log every step for detailed monitoring)\n",
    "\n",
    "- **MODEL_NAME**: Hugging Face model identifier for the student model\n",
    "  - \"Qwen/Qwen3-0.6B\": 600M parameter model (50x smaller than the 30B teacher)\n",
    "\n",
    "- **OUTPUT_DIR**: Directory where trained model checkpoints will be saved\n",
    "\n",
    "- **MAX_STEPS**: Maximum training steps\n",
    "  - Set to 5 if NEURON_EXTRACT_GRAPHS_ONLY=1 (for graph extraction/compilation testing)\n",
    "  - Set to -1 otherwise (train for full NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen/Qwen3-0.6B\n",
      "Output directory: Qwen3-0.6B-finetuned\n",
      "Max steps: -1\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "PROCESSES_PER_NODE = 2\n",
    "NUM_EPOCHS = 3\n",
    "TP_DEGREE = 2\n",
    "BS = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 16\n",
    "LOGGING_STEPS = 1\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "OUTPUT_DIR = f\"{MODEL_NAME.split('/')[-1]}-finetuned\"\n",
    "\n",
    "# Set max steps based on environment\n",
    "MAX_STEPS = 5 if os.environ.get('NEURON_EXTRACT_GRAPHS_ONLY') == '1' else -1\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Max steps: {MAX_STEPS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KnowledgeDistillationTrainer Code\n",
    "\n",
    "Let's examine the custom `KnowledgeDistillationTrainer` class from `distill_neuron_torchrun.py`.\n",
    "\n",
    "This trainer extends the Optimum Neuron `NeuronTrainer` class to implement knowledge distillation. The key innovation is in the `compute_loss` method, which combines two types of losses:\n",
    "\n",
    "**Class Structure:**\n",
    "\n",
    "```python\n",
    "class KnowledgeDistillationTrainer(NeuronTrainer):\n",
    "    def __init__(self, temperature=4.0, alpha=0.7, *args, **kwargs):\n",
    "```\n",
    "\n",
    "**Hyperparameters:**\n",
    "- **temperature** (default=4.0): Controls the \"softness\" of probability distributions\n",
    "  - Higher temperature = softer distributions (more uniform probabilities)\n",
    "  - Softer distributions reveal more about the teacher's uncertainty and reasoning\n",
    "  - Typical range: 2.0-10.0\n",
    "\n",
    "- **alpha** (default=0.7): Balances soft loss vs. hard loss\n",
    "  - alpha=0.7 means 70% weight on teacher's soft labels, 30% on true labels\n",
    "  - Higher alpha = more emphasis on mimicking the teacher\n",
    "  - Lower alpha = more emphasis on getting correct answers\n",
    "  - Typical range: 0.5-0.9\n",
    "\n",
    "The following cell displays the complete class implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".highlight .hll { background-color: #49483e }\n",
       ".highlight { background: #272822; color: #F8F8F2 }\n",
       ".highlight .c { color: #959077 } /* Comment */\n",
       ".highlight .err { color: #ED007E; background-color: #1E0010 } /* Error */\n",
       ".highlight .esc { color: #F8F8F2 } /* Escape */\n",
       ".highlight .g { color: #F8F8F2 } /* Generic */\n",
       ".highlight .k { color: #66D9EF } /* Keyword */\n",
       ".highlight .l { color: #AE81FF } /* Literal */\n",
       ".highlight .n { color: #F8F8F2 } /* Name */\n",
       ".highlight .o { color: #FF4689 } /* Operator */\n",
       ".highlight .x { color: #F8F8F2 } /* Other */\n",
       ".highlight .p { color: #F8F8F2 } /* Punctuation */\n",
       ".highlight .ch { color: #959077 } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #959077 } /* Comment.Multiline */\n",
       ".highlight .cp { color: #959077 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #959077 } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #959077 } /* Comment.Single */\n",
       ".highlight .cs { color: #959077 } /* Comment.Special */\n",
       ".highlight .gd { color: #FF4689 } /* Generic.Deleted */\n",
       ".highlight .ge { color: #F8F8F2; font-style: italic } /* Generic.Emph */\n",
       ".highlight .ges { color: #F8F8F2; font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".highlight .gr { color: #F8F8F2 } /* Generic.Error */\n",
       ".highlight .gh { color: #F8F8F2 } /* Generic.Heading */\n",
       ".highlight .gi { color: #A6E22E } /* Generic.Inserted */\n",
       ".highlight .go { color: #66D9EF } /* Generic.Output */\n",
       ".highlight .gp { color: #FF4689; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { color: #F8F8F2; font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #959077 } /* Generic.Subheading */\n",
       ".highlight .gt { color: #F8F8F2 } /* Generic.Traceback */\n",
       ".highlight .kc { color: #66D9EF } /* Keyword.Constant */\n",
       ".highlight .kd { color: #66D9EF } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #FF4689 } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #66D9EF } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #66D9EF } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #66D9EF } /* Keyword.Type */\n",
       ".highlight .ld { color: #E6DB74 } /* Literal.Date */\n",
       ".highlight .m { color: #AE81FF } /* Literal.Number */\n",
       ".highlight .s { color: #E6DB74 } /* Literal.String */\n",
       ".highlight .na { color: #A6E22E } /* Name.Attribute */\n",
       ".highlight .nb { color: #F8F8F2 } /* Name.Builtin */\n",
       ".highlight .nc { color: #A6E22E } /* Name.Class */\n",
       ".highlight .no { color: #66D9EF } /* Name.Constant */\n",
       ".highlight .nd { color: #A6E22E } /* Name.Decorator */\n",
       ".highlight .ni { color: #F8F8F2 } /* Name.Entity */\n",
       ".highlight .ne { color: #A6E22E } /* Name.Exception */\n",
       ".highlight .nf { color: #A6E22E } /* Name.Function */\n",
       ".highlight .nl { color: #F8F8F2 } /* Name.Label */\n",
       ".highlight .nn { color: #F8F8F2 } /* Name.Namespace */\n",
       ".highlight .nx { color: #A6E22E } /* Name.Other */\n",
       ".highlight .py { color: #F8F8F2 } /* Name.Property */\n",
       ".highlight .nt { color: #FF4689 } /* Name.Tag */\n",
       ".highlight .nv { color: #F8F8F2 } /* Name.Variable */\n",
       ".highlight .ow { color: #FF4689 } /* Operator.Word */\n",
       ".highlight .pm { color: #F8F8F2 } /* Punctuation.Marker */\n",
       ".highlight .w { color: #F8F8F2 } /* Text.Whitespace */\n",
       ".highlight .mb { color: #AE81FF } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #AE81FF } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #AE81FF } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #AE81FF } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #AE81FF } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #E6DB74 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #E6DB74 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #E6DB74 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #E6DB74 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #E6DB74 } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #E6DB74 } /* Literal.String.Double */\n",
       ".highlight .se { color: #AE81FF } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #E6DB74 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #E6DB74 } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #E6DB74 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #E6DB74 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #E6DB74 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #E6DB74 } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #F8F8F2 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #A6E22E } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #F8F8F2 } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #F8F8F2 } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #F8F8F2 } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #F8F8F2 } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #AE81FF } /* Literal.Number.Integer.Long */\n",
       "        .highlight { \n",
       "            background: #272822; \n",
       "            padding: 10px; \n",
       "            text-align: left;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "        .highlight pre { \n",
       "            text-align: left;\n",
       "            margin: 0;\n",
       "            color: #f8f8f2;\n",
       "        }\n",
       "        .linenos { \n",
       "            color: #75715e; \n",
       "            padding-right: 10px;\n",
       "            text-align: right;\n",
       "            -webkit-user-select: none;\n",
       "            -moz-user-select: none;\n",
       "            -ms-user-select: none;\n",
       "            user-select: none;\n",
       "        }\n",
       "        .highlight .hll { background-color: #49483e }\n",
       "        .highlight .c { color: #75715e } /* Comment */\n",
       "        .highlight .err { color: #960050; background-color: #1e0010 } /* Error */\n",
       "        .highlight .k { color: #66d9ef } /* Keyword */\n",
       "        .highlight .l { color: #ae81ff } /* Literal */\n",
       "        .highlight .n { color: #f8f8f2 } /* Name */\n",
       "        .highlight .o { color: #f92672 } /* Operator */\n",
       "        .highlight .p { color: #f8f8f2 } /* Punctuation */\n",
       "        .highlight .s { color: #e6db74 } /* String */\n",
       "        .highlight .na { color: #a6e22e } /* Name.Attribute */\n",
       "        .highlight .nb { color: #f8f8f2 } /* Name.Builtin */\n",
       "        .highlight .nc { color: #a6e22e } /* Name.Class */\n",
       "        .highlight .no { color: #66d9ef } /* Name.Constant */\n",
       "        .highlight .nd { color: #a6e22e } /* Name.Decorator */\n",
       "        .highlight .ni { color: #f8f8f2 } /* Name.Entity */\n",
       "        .highlight .ne { color: #a6e22e } /* Name.Exception */\n",
       "        .highlight .nf { color: #a6e22e } /* Name.Function */\n",
       "        .highlight .nl { color: #f8f8f2 } /* Name.Label */\n",
       "        .highlight .nn { color: #f8f8f2 } /* Name.Namespace */\n",
       "        .highlight .nx { color: #a6e22e } /* Name.Other */\n",
       "        .highlight .py { color: #f8f8f2 } /* Name.Property */\n",
       "        .highlight .nt { color: #f92672 } /* Name.Tag */\n",
       "        .highlight .nv { color: #f8f8f2 } /* Name.Variable */\n",
       "        .highlight .w { color: #f8f8f2 } /* Text.Whitespace */\n",
       "        </style>\n",
       "        <div class=\"highlight\"><table class=\"highlighttable\"><tr><td class=\"linenos\"><div class=\"linenodiv\"><pre><span class=\"normal\"><a href=\"#line-1\"> 1</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-2\"> 2</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-3\"> 3</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-4\"> 4</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-5\"> 5</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-6\"> 6</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-7\"> 7</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-8\"> 8</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-9\"> 9</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-10\">10</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-11\">11</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-12\">12</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-13\">13</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-14\">14</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-15\">15</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-16\">16</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-17\">17</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-18\">18</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-19\">19</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-20\">20</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-21\">21</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-22\">22</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-23\">23</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-24\">24</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-25\">25</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-26\">26</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-27\">27</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-28\">28</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-29\">29</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-30\">30</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-31\">31</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-32\">32</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-33\">33</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-34\">34</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-35\">35</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-36\">36</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-37\">37</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-38\">38</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-39\">39</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-40\">40</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-41\">41</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-42\">42</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-43\">43</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-44\">44</a></span></pre></div></td><td class=\"code\"><div><pre><span></span><a id=\"line-1\" name=\"line-1\"></a><span class=\"c1\"># =============================================================================</span>\n",
       "<a id=\"line-2\" name=\"line-2\"></a><span class=\"k\">class</span><span class=\"w\"> </span><span class=\"nc\">KnowledgeDistillationTrainer</span><span class=\"p\">(</span><span class=\"n\">NeuronTrainer</span><span class=\"p\">):</span>\n",
       "<a id=\"line-3\" name=\"line-3\"></a>    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mf\">4.0</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n",
       "<a id=\"line-4\" name=\"line-4\"></a>        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n",
       "<a id=\"line-5\" name=\"line-5\"></a>        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">temperature</span> <span class=\"o\">=</span> <span class=\"n\">temperature</span>\n",
       "<a id=\"line-6\" name=\"line-6\"></a>        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">alpha</span> <span class=\"o\">=</span> <span class=\"n\">alpha</span>\n",
       "<a id=\"line-7\" name=\"line-7\"></a>    \n",
       "<a id=\"line-8\" name=\"line-8\"></a>    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">compute_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">return_outputs</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">num_items_in_batch</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
       "<a id=\"line-9\" name=\"line-9\"></a><span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<a id=\"line-10\" name=\"line-10\"></a><span class=\"sd\">        Compute knowledge distillation loss combining:</span>\n",
       "<a id=\"line-11\" name=\"line-11\"></a><span class=\"sd\">        - Hard loss: standard cross-entropy with true labels</span>\n",
       "<a id=\"line-12\" name=\"line-12\"></a><span class=\"sd\">        - Soft loss: KL divergence between teacher and student logits</span>\n",
       "<a id=\"line-13\" name=\"line-13\"></a><span class=\"sd\">        &quot;&quot;&quot;</span>\n",
       "<a id=\"line-14\" name=\"line-14\"></a>        <span class=\"k\">if</span> <span class=\"n\">num_items_in_batch</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
       "<a id=\"line-15\" name=\"line-15\"></a>        <span class=\"c1\"># Do something with num_items_in_batch</span>\n",
       "<a id=\"line-16\" name=\"line-16\"></a>            <span class=\"k\">pass</span>\n",
       "<a id=\"line-17\" name=\"line-17\"></a>        \n",
       "<a id=\"line-18\" name=\"line-18\"></a>        <span class=\"n\">student_outputs</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span>\n",
       "<a id=\"line-19\" name=\"line-19\"></a>            <span class=\"n\">input_ids</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;input_ids&#39;</span><span class=\"p\">],</span>\n",
       "<a id=\"line-20\" name=\"line-20\"></a>            <span class=\"n\">attention_mask</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;attention_mask&#39;</span><span class=\"p\">]</span>\n",
       "<a id=\"line-21\" name=\"line-21\"></a>        <span class=\"p\">)</span>\n",
       "<a id=\"line-22\" name=\"line-22\"></a>        <span class=\"n\">student_logits</span> <span class=\"o\">=</span> <span class=\"n\">student_outputs</span><span class=\"o\">.</span><span class=\"n\">logits</span>\n",
       "<a id=\"line-23\" name=\"line-23\"></a>        \n",
       "<a id=\"line-24\" name=\"line-24\"></a>        <span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">k</span><span class=\"p\">:</span> <span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"s1\">&#39;xla&#39;</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">is_tensor</span><span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"k\">else</span> <span class=\"n\">v</span> <span class=\"k\">for</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"ow\">in</span> <span class=\"n\">inputs</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<a id=\"line-25\" name=\"line-25\"></a>        \n",
       "<a id=\"line-26\" name=\"line-26\"></a>        <span class=\"c1\"># Hard loss (standard language modeling loss)</span>\n",
       "<a id=\"line-27\" name=\"line-27\"></a>        <span class=\"n\">hard_loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span>\n",
       "<a id=\"line-28\" name=\"line-28\"></a>            <span class=\"n\">student_logits</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">student_logits</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)),</span>\n",
       "<a id=\"line-29\" name=\"line-29\"></a>            <span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;labels&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<a id=\"line-30\" name=\"line-30\"></a>        <span class=\"p\">)</span>\n",
       "<a id=\"line-31\" name=\"line-31\"></a>        \n",
       "<a id=\"line-32\" name=\"line-32\"></a>        <span class=\"c1\"># Soft loss (knowledge distillation)</span>\n",
       "<a id=\"line-33\" name=\"line-33\"></a>        <span class=\"n\">student_soft</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">log_softmax</span><span class=\"p\">(</span><span class=\"n\">student_logits</span> <span class=\"o\">/</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">temperature</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<a id=\"line-34\" name=\"line-34\"></a>        <span class=\"n\">teacher_soft</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;teacher_logits&#39;</span><span class=\"p\">]</span> <span class=\"o\">/</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">temperature</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<a id=\"line-35\" name=\"line-35\"></a>        \n",
       "<a id=\"line-36\" name=\"line-36\"></a>        <span class=\"n\">soft_loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">kl_div</span><span class=\"p\">(</span>\n",
       "<a id=\"line-37\" name=\"line-37\"></a>            <span class=\"n\">student_soft</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">student_soft</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)),</span>\n",
       "<a id=\"line-38\" name=\"line-38\"></a>            <span class=\"n\">teacher_soft</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">teacher_soft</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)),</span>\n",
       "<a id=\"line-39\" name=\"line-39\"></a>            <span class=\"n\">reduction</span><span class=\"o\">=</span><span class=\"s1\">&#39;batchmean&#39;</span>\n",
       "<a id=\"line-40\" name=\"line-40\"></a>        <span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">temperature</span> <span class=\"o\">**</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n",
       "<a id=\"line-41\" name=\"line-41\"></a>        \n",
       "<a id=\"line-42\" name=\"line-42\"></a>        <span class=\"c1\"># Combined loss</span>\n",
       "<a id=\"line-43\" name=\"line-43\"></a>        <span class=\"n\">total_loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">alpha</span> <span class=\"o\">*</span> <span class=\"n\">soft_loss</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"o\">-</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">alpha</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">hard_loss</span>\n",
       "<a id=\"line-44\" name=\"line-44\"></a>        \n",
       "</pre></div></td></tr></table></div>\n",
       "\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettyprint_python(\"src/distill_neuron_torchrun.py\", line_numbers=True, line_range=(35, 78))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Methods of KnowledgeDistillationTrainer\n",
    "\n",
    "The `compute_loss` method is the core of the knowledge distillation process. Let's break down how it works:\n",
    "\n",
    "**Step 1: Generate Student Predictions**\n",
    "```python\n",
    "student_outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "student_logits = student_outputs.logits\n",
    "```\n",
    "Run the student model to get its predictions (logits) for the input text.\n",
    "\n",
    "**Step 2: Compute Hard Loss**\n",
    "```python\n",
    "hard_loss = F.cross_entropy(student_logits.view(-1, student_logits.size(-1)), inputs['labels'].view(-1))\n",
    "```\n",
    "Standard cross-entropy loss comparing student predictions to true labels (POSITIVE/NEGATIVE/NEUTRAL).\n",
    "This ensures the student learns to produce correct answers.\n",
    "\n",
    "**Step 3: Compute Soft Loss**\n",
    "```python\n",
    "student_soft = F.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "teacher_soft = F.softmax(inputs['teacher_logits'] / self.temperature, dim=-1)\n",
    "soft_loss = F.kl_div(student_soft, teacher_soft, reduction='batchmean') * (self.temperature ** 2)\n",
    "```\n",
    "- Apply temperature scaling to both student and teacher logits (makes distributions softer)\n",
    "- Compute KL divergence: measures how different the student's distribution is from the teacher's\n",
    "- Multiply by temperature² to maintain gradient scale (mathematical requirement of distillation)\n",
    "\n",
    "**Step 4: Combine Losses**\n",
    "```python\n",
    "total_loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
    "```\n",
    "Weighted combination of soft and hard losses.\n",
    "\n",
    "**Example:**\n",
    "For input \"This phone's battery life is absolutely amazing!\":\n",
    "- Hard loss: Penalizes if student doesn't predict \"POSITIVE\"\n",
    "- Soft loss: Penalizes if student's confidence distribution differs from teacher's (e.g., teacher might be 95% confident POSITIVE, 4% NEUTRAL, 1% NEGATIVE)\n",
    "\n",
    "The following cell displays the complete `compute_loss` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".highlight .hll { background-color: #49483e }\n",
       ".highlight { background: #272822; color: #F8F8F2 }\n",
       ".highlight .c { color: #959077 } /* Comment */\n",
       ".highlight .err { color: #ED007E; background-color: #1E0010 } /* Error */\n",
       ".highlight .esc { color: #F8F8F2 } /* Escape */\n",
       ".highlight .g { color: #F8F8F2 } /* Generic */\n",
       ".highlight .k { color: #66D9EF } /* Keyword */\n",
       ".highlight .l { color: #AE81FF } /* Literal */\n",
       ".highlight .n { color: #F8F8F2 } /* Name */\n",
       ".highlight .o { color: #FF4689 } /* Operator */\n",
       ".highlight .x { color: #F8F8F2 } /* Other */\n",
       ".highlight .p { color: #F8F8F2 } /* Punctuation */\n",
       ".highlight .ch { color: #959077 } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #959077 } /* Comment.Multiline */\n",
       ".highlight .cp { color: #959077 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #959077 } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #959077 } /* Comment.Single */\n",
       ".highlight .cs { color: #959077 } /* Comment.Special */\n",
       ".highlight .gd { color: #FF4689 } /* Generic.Deleted */\n",
       ".highlight .ge { color: #F8F8F2; font-style: italic } /* Generic.Emph */\n",
       ".highlight .ges { color: #F8F8F2; font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".highlight .gr { color: #F8F8F2 } /* Generic.Error */\n",
       ".highlight .gh { color: #F8F8F2 } /* Generic.Heading */\n",
       ".highlight .gi { color: #A6E22E } /* Generic.Inserted */\n",
       ".highlight .go { color: #66D9EF } /* Generic.Output */\n",
       ".highlight .gp { color: #FF4689; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { color: #F8F8F2; font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #959077 } /* Generic.Subheading */\n",
       ".highlight .gt { color: #F8F8F2 } /* Generic.Traceback */\n",
       ".highlight .kc { color: #66D9EF } /* Keyword.Constant */\n",
       ".highlight .kd { color: #66D9EF } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #FF4689 } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #66D9EF } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #66D9EF } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #66D9EF } /* Keyword.Type */\n",
       ".highlight .ld { color: #E6DB74 } /* Literal.Date */\n",
       ".highlight .m { color: #AE81FF } /* Literal.Number */\n",
       ".highlight .s { color: #E6DB74 } /* Literal.String */\n",
       ".highlight .na { color: #A6E22E } /* Name.Attribute */\n",
       ".highlight .nb { color: #F8F8F2 } /* Name.Builtin */\n",
       ".highlight .nc { color: #A6E22E } /* Name.Class */\n",
       ".highlight .no { color: #66D9EF } /* Name.Constant */\n",
       ".highlight .nd { color: #A6E22E } /* Name.Decorator */\n",
       ".highlight .ni { color: #F8F8F2 } /* Name.Entity */\n",
       ".highlight .ne { color: #A6E22E } /* Name.Exception */\n",
       ".highlight .nf { color: #A6E22E } /* Name.Function */\n",
       ".highlight .nl { color: #F8F8F2 } /* Name.Label */\n",
       ".highlight .nn { color: #F8F8F2 } /* Name.Namespace */\n",
       ".highlight .nx { color: #A6E22E } /* Name.Other */\n",
       ".highlight .py { color: #F8F8F2 } /* Name.Property */\n",
       ".highlight .nt { color: #FF4689 } /* Name.Tag */\n",
       ".highlight .nv { color: #F8F8F2 } /* Name.Variable */\n",
       ".highlight .ow { color: #FF4689 } /* Operator.Word */\n",
       ".highlight .pm { color: #F8F8F2 } /* Punctuation.Marker */\n",
       ".highlight .w { color: #F8F8F2 } /* Text.Whitespace */\n",
       ".highlight .mb { color: #AE81FF } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #AE81FF } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #AE81FF } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #AE81FF } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #AE81FF } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #E6DB74 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #E6DB74 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #E6DB74 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #E6DB74 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #E6DB74 } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #E6DB74 } /* Literal.String.Double */\n",
       ".highlight .se { color: #AE81FF } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #E6DB74 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #E6DB74 } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #E6DB74 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #E6DB74 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #E6DB74 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #E6DB74 } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #F8F8F2 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #A6E22E } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #F8F8F2 } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #F8F8F2 } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #F8F8F2 } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #F8F8F2 } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #AE81FF } /* Literal.Number.Integer.Long */\n",
       "        .highlight { \n",
       "            background: #272822; \n",
       "            padding: 10px; \n",
       "            text-align: left;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "        .highlight pre { \n",
       "            text-align: left;\n",
       "            margin: 0;\n",
       "            color: #f8f8f2;\n",
       "        }\n",
       "        .linenos { \n",
       "            color: #75715e; \n",
       "            padding-right: 10px;\n",
       "            text-align: right;\n",
       "            -webkit-user-select: none;\n",
       "            -moz-user-select: none;\n",
       "            -ms-user-select: none;\n",
       "            user-select: none;\n",
       "        }\n",
       "        .highlight .hll { background-color: #49483e }\n",
       "        .highlight .c { color: #75715e } /* Comment */\n",
       "        .highlight .err { color: #960050; background-color: #1e0010 } /* Error */\n",
       "        .highlight .k { color: #66d9ef } /* Keyword */\n",
       "        .highlight .l { color: #ae81ff } /* Literal */\n",
       "        .highlight .n { color: #f8f8f2 } /* Name */\n",
       "        .highlight .o { color: #f92672 } /* Operator */\n",
       "        .highlight .p { color: #f8f8f2 } /* Punctuation */\n",
       "        .highlight .s { color: #e6db74 } /* String */\n",
       "        .highlight .na { color: #a6e22e } /* Name.Attribute */\n",
       "        .highlight .nb { color: #f8f8f2 } /* Name.Builtin */\n",
       "        .highlight .nc { color: #a6e22e } /* Name.Class */\n",
       "        .highlight .no { color: #66d9ef } /* Name.Constant */\n",
       "        .highlight .nd { color: #a6e22e } /* Name.Decorator */\n",
       "        .highlight .ni { color: #f8f8f2 } /* Name.Entity */\n",
       "        .highlight .ne { color: #a6e22e } /* Name.Exception */\n",
       "        .highlight .nf { color: #a6e22e } /* Name.Function */\n",
       "        .highlight .nl { color: #f8f8f2 } /* Name.Label */\n",
       "        .highlight .nn { color: #f8f8f2 } /* Name.Namespace */\n",
       "        .highlight .nx { color: #a6e22e } /* Name.Other */\n",
       "        .highlight .py { color: #f8f8f2 } /* Name.Property */\n",
       "        .highlight .nt { color: #f92672 } /* Name.Tag */\n",
       "        .highlight .nv { color: #f8f8f2 } /* Name.Variable */\n",
       "        .highlight .w { color: #f8f8f2 } /* Text.Whitespace */\n",
       "        </style>\n",
       "        <div class=\"highlight\"><table class=\"highlighttable\"><tr><td class=\"linenos\"><div class=\"linenodiv\"><pre><span class=\"normal\"><a href=\"#line-1\"> 1</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-2\"> 2</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-3\"> 3</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-4\"> 4</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-5\"> 5</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-6\"> 6</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-7\"> 7</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-8\"> 8</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-9\"> 9</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-10\">10</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-11\">11</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-12\">12</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-13\">13</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-14\">14</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-15\">15</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-16\">16</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-17\">17</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-18\">18</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-19\">19</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-20\">20</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-21\">21</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-22\">22</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-23\">23</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-24\">24</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-25\">25</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-26\">26</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-27\">27</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-28\">28</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-29\">29</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-30\">30</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-31\">31</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-32\">32</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-33\">33</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-34\">34</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-35\">35</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-36\">36</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-37\">37</a></span>\n",
       "<span class=\"normal\"><a href=\"#line-38\">38</a></span></pre></div></td><td class=\"code\"><div><pre><span></span><a id=\"line-1\" name=\"line-1\"></a>    \n",
       "<a id=\"line-2\" name=\"line-2\"></a>    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">compute_loss</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">return_outputs</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">num_items_in_batch</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
       "<a id=\"line-3\" name=\"line-3\"></a><span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<a id=\"line-4\" name=\"line-4\"></a><span class=\"sd\">        Compute knowledge distillation loss combining:</span>\n",
       "<a id=\"line-5\" name=\"line-5\"></a><span class=\"sd\">        - Hard loss: standard cross-entropy with true labels</span>\n",
       "<a id=\"line-6\" name=\"line-6\"></a><span class=\"sd\">        - Soft loss: KL divergence between teacher and student logits</span>\n",
       "<a id=\"line-7\" name=\"line-7\"></a><span class=\"sd\">        &quot;&quot;&quot;</span>\n",
       "<a id=\"line-8\" name=\"line-8\"></a>        <span class=\"k\">if</span> <span class=\"n\">num_items_in_batch</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
       "<a id=\"line-9\" name=\"line-9\"></a>        <span class=\"c1\"># Do something with num_items_in_batch</span>\n",
       "<a id=\"line-10\" name=\"line-10\"></a>            <span class=\"k\">pass</span>\n",
       "<a id=\"line-11\" name=\"line-11\"></a>        \n",
       "<a id=\"line-12\" name=\"line-12\"></a>        <span class=\"n\">student_outputs</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span>\n",
       "<a id=\"line-13\" name=\"line-13\"></a>            <span class=\"n\">input_ids</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;input_ids&#39;</span><span class=\"p\">],</span>\n",
       "<a id=\"line-14\" name=\"line-14\"></a>            <span class=\"n\">attention_mask</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;attention_mask&#39;</span><span class=\"p\">]</span>\n",
       "<a id=\"line-15\" name=\"line-15\"></a>        <span class=\"p\">)</span>\n",
       "<a id=\"line-16\" name=\"line-16\"></a>        <span class=\"n\">student_logits</span> <span class=\"o\">=</span> <span class=\"n\">student_outputs</span><span class=\"o\">.</span><span class=\"n\">logits</span>\n",
       "<a id=\"line-17\" name=\"line-17\"></a>        \n",
       "<a id=\"line-18\" name=\"line-18\"></a>        <span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">k</span><span class=\"p\">:</span> <span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"s1\">&#39;xla&#39;</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">is_tensor</span><span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"k\">else</span> <span class=\"n\">v</span> <span class=\"k\">for</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"ow\">in</span> <span class=\"n\">inputs</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()}</span>\n",
       "<a id=\"line-19\" name=\"line-19\"></a>        \n",
       "<a id=\"line-20\" name=\"line-20\"></a>        <span class=\"c1\"># Hard loss (standard language modeling loss)</span>\n",
       "<a id=\"line-21\" name=\"line-21\"></a>        <span class=\"n\">hard_loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span>\n",
       "<a id=\"line-22\" name=\"line-22\"></a>            <span class=\"n\">student_logits</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">student_logits</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)),</span>\n",
       "<a id=\"line-23\" name=\"line-23\"></a>            <span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;labels&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<a id=\"line-24\" name=\"line-24\"></a>        <span class=\"p\">)</span>\n",
       "<a id=\"line-25\" name=\"line-25\"></a>        \n",
       "<a id=\"line-26\" name=\"line-26\"></a>        <span class=\"c1\"># Soft loss (knowledge distillation)</span>\n",
       "<a id=\"line-27\" name=\"line-27\"></a>        <span class=\"n\">student_soft</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">log_softmax</span><span class=\"p\">(</span><span class=\"n\">student_logits</span> <span class=\"o\">/</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">temperature</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<a id=\"line-28\" name=\"line-28\"></a>        <span class=\"n\">teacher_soft</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;teacher_logits&#39;</span><span class=\"p\">]</span> <span class=\"o\">/</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">temperature</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<a id=\"line-29\" name=\"line-29\"></a>        \n",
       "<a id=\"line-30\" name=\"line-30\"></a>        <span class=\"n\">soft_loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">kl_div</span><span class=\"p\">(</span>\n",
       "<a id=\"line-31\" name=\"line-31\"></a>            <span class=\"n\">student_soft</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">student_soft</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)),</span>\n",
       "<a id=\"line-32\" name=\"line-32\"></a>            <span class=\"n\">teacher_soft</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">teacher_soft</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)),</span>\n",
       "<a id=\"line-33\" name=\"line-33\"></a>            <span class=\"n\">reduction</span><span class=\"o\">=</span><span class=\"s1\">&#39;batchmean&#39;</span>\n",
       "<a id=\"line-34\" name=\"line-34\"></a>        <span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">temperature</span> <span class=\"o\">**</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n",
       "<a id=\"line-35\" name=\"line-35\"></a>        \n",
       "<a id=\"line-36\" name=\"line-36\"></a>        <span class=\"c1\"># Combined loss</span>\n",
       "<a id=\"line-37\" name=\"line-37\"></a>        <span class=\"n\">total_loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">alpha</span> <span class=\"o\">*</span> <span class=\"n\">soft_loss</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"o\">-</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">alpha</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">hard_loss</span>\n",
       "<a id=\"line-38\" name=\"line-38\"></a>        \n",
       "</pre></div></td></tr></table></div>\n",
       "\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettyprint_python(\"src/distill_neuron_torchrun.py\", line_numbers=True, line_range=(41, 78))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Distillation Training\n",
    "\n",
    "Execute the distributed training job using `torchrun`, PyTorch's distributed training launcher.\n",
    "\n",
    "**Why torchrun?**\n",
    "- Manages multiple training processes automatically\n",
    "- Sets up distributed communication between processes\n",
    "- Handles process synchronization and fault tolerance\n",
    "\n",
    "**Command Structure:**\n",
    "\n",
    "```bash\n",
    "torchrun --nproc_per_node 2 src/distill_neuron_torchrun.py [training args]\n",
    "```\n",
    "\n",
    "**Key Arguments:**\n",
    "\n",
    "- **--nproc_per_node**: Number of processes to launch (2 = data parallel training across 2 processes)\n",
    "- **--model_id**: Student model to train (Qwen/Qwen3-0.6B)\n",
    "- **--num_train_epochs**: Number of complete passes through the dataset (3)\n",
    "- **--do_train**: Enable training mode\n",
    "- **--max_steps**: Maximum training steps (-1 = train for full epochs, 5 = quick test)\n",
    "- **--per_device_train_batch_size**: Batch size per device (1)\n",
    "- **--gradient_accumulation_steps**: Accumulate gradients over 16 steps (effective batch size = 16)\n",
    "- **--learning_rate**: Optimizer learning rate (1e-4 = 0.0001, conservative for distillation)\n",
    "- **--bf16**: Use BFloat16 precision (faster training, lower memory, minimal accuracy loss)\n",
    "- **--tensor_parallel_size**: Distribute model across 2 NeuronCores per process\n",
    "- **--warmup_steps**: Gradually increase learning rate over first 5 steps (stabilizes training)\n",
    "- **--pipeline_parallel_size**: No pipeline parallelism (1 = disabled)\n",
    "- **--logging_steps**: Log metrics every step for detailed monitoring\n",
    "- **--output_dir**: Where to save model checkpoints\n",
    "- **--overwrite_output_dir**: Overwrite existing checkpoints if present\n",
    "\n",
    "**Training Process:**\n",
    "\n",
    "1. **Compilation Phase** (first run only, ~20-30 minutes):\n",
    "   - Neuron compiler optimizes the model for Trainium hardware\n",
    "   - Generates NEFF (Neuron Executable File Format) files\n",
    "   - Cached for subsequent runs\n",
    "\n",
    "2. **Training Phase** (~10-15 minutes):\n",
    "   - Loads teacher logits from `data/output1.json`\n",
    "   - Trains student model using knowledge distillation\n",
    "   - Saves checkpoints to OUTPUT_DIR\n",
    "\n",
    "3. **Final Model** saved to `./final_distilled_model`\n",
    "\n",
    "**Monitoring Training:**\n",
    "- Watch for loss values decreasing over time\n",
    "- Soft loss and hard loss are logged separately\n",
    "- Training is complete when you see \"Training completed\" message\n",
    "\n",
    "**Note:** The first run will take significantly longer due to compilation. Be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\n",
      "torchrun --nproc_per_node 2 src/distill_neuron_torchrun.py --model_id Qwen/Qwen3-0.6B --num_train_epochs 3 --do_train --max_steps -1 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 1e-4 --bf16 --zero_1 False --tensor_parallel_size 2 --warmup_steps 5 --pipeline_parallel_size 1 --logging_steps 1 --output_dir Qwen3-0.6B-finetuned --overwrite_output_dir\n",
      "\n",
      "==================================================\n",
      "STDOUT:\n",
      "2025-Oct-28 20:31:41.0814 15009:15033 [0] net_plugin.cc:73 CCOM WARN NET/Plugin: Error: libnccom-net.so load failed. libfabric.so.1: cannot open shared object file: No such file or directory. Please make sure to install the latest version of libfabric from https://efa-installer.amazonaws.com/aws-efa-installer-latest.tar.gz.\n",
      "2025-Oct-28 20:31:46.0910 15010:15076 [1] net_plugin.cc:73 CCOM WARN NET/Plugin: Error: libnccom-net.so load failed. libfabric.so.1: cannot open shared object file: No such file or directory. Please make sure to install the latest version of libfabric from https://efa-installer.amazonaws.com/aws-efa-installer-latest.tar.gz.\n",
      "[2025-10-28 20:31:46.916: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 2\n",
      "[2025-10-28 20:31:46.916: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1\n",
      "[2025-10-28 20:31:46.916: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1\n",
      "[2025-10-28 20:31:46.917: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1\n",
      "[2025-10-28 20:31:46.917: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 2\n",
      "2025-10-28 20:31:46.000928:  15010  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a30e2dff-3425-4fb9-a9c7-4326bfd0f2c9/model.MODULE_4216092561315976987+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a30e2dff-3425-4fb9-a9c7-4326bfd0f2c9/model.MODULE_4216092561315976987+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "TrainingNeuronConfig(tensor_parallel_size=2, sequence_parallel_enabled=True, kv_size_multiplier=None, pipeline_parallel_size=1, virtual_pipeline_parallel_size=1, pipeline_parallel_num_microbatches=-1, pipeline_parallel_use_zero1_optimizer=False, gradient_checkpointing=False, checkpoint_dir=None, num_local_ranks_per_step=8, use_xser=True, async_save=False, fuse_qkv=False, recompute_causal_mask=True, transpose_nki_inputs=True)\n",
      "2025-10-28 20:31:51.000932:  15009  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_4216092561315976987+bad9cf09/model.neff\n",
      "[2025-10-28 20:31:51.968: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x791023693be0>, 'Ascending Ring PG Group')>\n",
      "[2025-10-28 20:31:51.968: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-10-28 20:31:51.968: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-10-28 20:31:51.968: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-10-28 20:31:51.969: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1]]\n",
      "[2025-10-28 20:31:51.969: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-10-28 20:31:51.969: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n",
      "TrainingNeuronConfig(tensor_parallel_size=2, sequence_parallel_enabled=True, kv_size_multiplier=None, pipeline_parallel_size=1, virtual_pipeline_parallel_size=1, pipeline_parallel_num_microbatches=-1, pipeline_parallel_use_zero1_optimizer=False, gradient_checkpointing=False, checkpoint_dir=None, num_local_ranks_per_step=8, use_xser=True, async_save=False, fuse_qkv=False, recompute_causal_mask=True, transpose_nki_inputs=True)\n",
      "2025-10-28 20:31:57.000222:  15009  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/242a554d-5dc5-4f71-8fba-77fb32c82b9a/model.MODULE_11196433285822111861+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/242a554d-5dc5-4f71-8fba-77fb32c82b9a/model.MODULE_11196433285822111861+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-10-28 20:32:02.000254:  15010  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_11196433285822111861+bad9cf09/model.neff\n",
      "2025-10-28 20:32:13.000898:  15009  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a854322c-3f02-46c5-bb60-be771a932dcb/model.MODULE_17244610172249175385+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a854322c-3f02-46c5-bb60-be771a932dcb/model.MODULE_17244610172249175385+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      ".2025-10-28 20:32:16.000810:  15010  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/ee3a7aa9-0010-4f83-9e1d-2a72d6fd39a0/model.MODULE_3876370926838788815+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/ee3a7aa9-0010-4f83-9e1d-2a72d6fd39a0/model.MODULE_3876370926838788815+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      ".......................................................................Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-10-28 20:44:14.000666:  15009  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e4234972-4876-4c8a-b3ee-d25fb17c6a08/model.MODULE_6877101459563117558+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e4234972-4876-4c8a-b3ee-d25fb17c6a08/model.MODULE_6877101459563117558+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      ".2025-10-28 20:44:17.000276:  15010  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/be97c3a8-06ad-4d1b-8138-e06e4d426751/model.MODULE_8623340492324789537+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/be97c3a8-06ad-4d1b-8138-e06e4d426751/model.MODULE_8623340492324789537+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      ".............................................................................Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-10-28 20:57:12.000340:  15010  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/2b531344-0333-429a-9715-81da935b40e5/model.MODULE_1193724274029669226+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/2b531344-0333-429a-9715-81da935b40e5/model.MODULE_1193724274029669226+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      "...2025-10-28 20:58:12.000389:  15009  INFO ||NEURON_CACHE||: Another process must be compiling /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_1193724274029669226+bad9cf09/model.hlo_module.pb, been waiting for: 1.0 minutes\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-10-28 20:58:37.000440:  15009  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_1193724274029669226+bad9cf09/model.neff\n",
      "2025-10-28 20:58:46.000117:  15010  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/03b6608a-5d3f-4c2c-8150-4614f8babec9/model.MODULE_14232261780857735320+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/03b6608a-5d3f-4c2c-8150-4614f8babec9/model.MODULE_14232261780857735320+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-10-28 20:58:50.000912:  15009  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_14232261780857735320+bad9cf09/model.neff\n",
      "{'loss': 4.822, 'learning_rate': 2e-05, 'grad_norm': 103.5, 'epoch': 0.16}\n",
      "2025-10-28 20:58:54.000581:  15010  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/84af5294-e557-4eec-8957-ec68e20822f7/model.MODULE_2974321072334943081+bad9cf09.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/84af5294-e557-4eec-8957-ec68e20822f7/model.MODULE_2974321072334943081+bad9cf09.neff --target=trn2 --model-type transformer --verbose=35\n",
      "...2025-10-28 20:59:54.000655:  15009  INFO ||NEURON_CACHE||: Another process must be compiling /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_2974321072334943081+bad9cf09/model.hlo_module.pb, been waiting for: 1.0 minutes\n",
      "...2025-10-28 21:00:54.000717:  15009  INFO ||NEURON_CACHE||: Another process must be compiling /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_2974321072334943081+bad9cf09/model.hlo_module.pb, been waiting for: 2.0 minutes\n",
      "...Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-10-28 21:01:44.000820:  15009  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_2974321072334943081+bad9cf09/model.neff\n",
      "{'loss': 4.773, 'learning_rate': 4e-05, 'grad_norm': 102.0, 'epoch': 0.32}\n",
      "{'loss': 3.0028, 'learning_rate': 6e-05, 'grad_norm': 67.5, 'epoch': 0.48}\n",
      "{'loss': 1.2865, 'learning_rate': 8e-05, 'grad_norm': 35.5, 'epoch': 0.64}\n",
      "{'loss': 0.6459, 'learning_rate': 0.0001, 'grad_norm': 26.25, 'epoch': 0.8}\n",
      "{'loss': 0.6586, 'learning_rate': 9.375e-05, 'grad_norm': 54.0, 'epoch': 0.96}\n",
      "{'loss': 0.3524, 'learning_rate': 8.75e-05, 'grad_norm': 37.25, 'epoch': 1.0}\n",
      "{'loss': 0.3026, 'learning_rate': 8.125000000000001e-05, 'grad_norm': 43.5, 'epoch': 1.16}\n",
      "{'loss': 0.168, 'learning_rate': 7.500000000000001e-05, 'grad_norm': 55.75, 'epoch': 1.32}\n",
      "{'loss': 0.1227, 'learning_rate': 6.875e-05, 'grad_norm': 10.625, 'epoch': 1.48}\n",
      "{'loss': 0.07, 'learning_rate': 6.25e-05, 'grad_norm': 4.375, 'epoch': 1.64}\n",
      "{'loss': 0.058, 'learning_rate': 5.6250000000000005e-05, 'grad_norm': 1.890625, 'epoch': 1.8}\n",
      "{'loss': 0.0571, 'learning_rate': 5e-05, 'grad_norm': 1.7421875, 'epoch': 1.96}\n",
      "{'loss': 0.0548, 'learning_rate': 4.375e-05, 'grad_norm': 1.90625, 'epoch': 2.0}\n",
      "{'loss': 0.057, 'learning_rate': 3.7500000000000003e-05, 'grad_norm': 2.015625, 'epoch': 2.16}\n",
      "{'loss': 0.0591, 'learning_rate': 3.125e-05, 'grad_norm': 1.9140625, 'epoch': 2.32}\n",
      "{'loss': 0.0463, 'learning_rate': 2.5e-05, 'grad_norm': 0.97265625, 'epoch': 2.48}\n",
      "{'loss': 0.0481, 'learning_rate': 1.8750000000000002e-05, 'grad_norm': 0.87890625, 'epoch': 2.64}\n",
      "{'loss': 0.0535, 'learning_rate': 1.25e-05, 'grad_norm': 1.5390625, 'epoch': 2.8}\n",
      "{'loss': 0.047, 'learning_rate': 6.25e-06, 'grad_norm': 1.03125, 'epoch': 2.96}\n",
      "{'loss': 0.0423, 'learning_rate': 0.0, 'grad_norm': 1.5234375, 'epoch': 3.0}\n",
      "[2025-10-28 21:06:11.339: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint shards began\n",
      "[2025-10-28 21:06:14.343: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint shards completed\n",
      "[2025-10-28 21:06:14.346: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "[2025-10-28 21:06:14.469: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint shards began\n",
      "[2025-10-28 21:06:17.379: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint shards completed\n",
      "[2025-10-28 21:06:17.381: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "\n",
      "\n",
      "STDERR:\n",
      "W1028 20:31:33.659000 14996 torch/distributed/run.py:774] \n",
      "W1028 20:31:33.659000 14996 torch/distributed/run.py:774] *****************************************\n",
      "W1028 20:31:33.659000 14996 torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1028 20:31:33.659000 14996 torch/distributed/run.py:774] *****************************************\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:70: UserWarning: Warning: Failed to import blockwise_mm_baseline_shard_n_k1_while_2loops: No module named 'neuronxcc.nki._private_kernels.blockwise_matmul_while'\n",
      "  warnings.warn(f\"Warning: {error}\")\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:70: UserWarning: Warning: Failed to import blockwise_mm_baseline_shard_n_k1_while_2loops: No module named 'neuronxcc.nki._private_kernels.blockwise_matmul_while'\n",
      "  warnings.warn(f\"Warning: {error}\")\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "2025-10-28 20:31:38.731768: W neuron/pjrt-api/neuronpjrt.cc:1972] Use PJRT C-API 0.73 as client did not specify a PJRT C-API version\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "2025-10-28 20:31:38.741170: W neuron/pjrt-api/neuronpjrt.cc:1972] Use PJRT C-API 0.73 as client did not specify a PJRT C-API version\n",
      "PyTorch: setting up devices\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:33: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "loading weights file model.safetensors from cache at /home/ubuntu/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/c1899de289a04d12100db370d81485cdf75e47ca/model.safetensors\n",
      "PyTorch: setting up devices\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:33: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "loading weights file model.safetensors from cache at /home/ubuntu/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/c1899de289a04d12100db370d81485cdf75e47ca/model.safetensors\n",
      "All model checkpoint weights were used when initializing Qwen3ForCausalLM.\n",
      "\n",
      "All the weights of Qwen3ForCausalLM were initialized from the model checkpoint at Qwen/Qwen3-0.6B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3ForCausalLM for predictions without further training.\n",
      "All model checkpoint weights were used when initializing Qwen3ForCausalLM.\n",
      "\n",
      "All the weights of Qwen3ForCausalLM were initialized from the model checkpoint at Qwen/Qwen3-0.6B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3ForCausalLM for predictions without further training.\n",
      "`even_batches` in `AcceleratorConfig` is not supported in NeuronTrainer and will be ignored. Make sure that your dataset size is divisible by the train batch size x gradient accumulation steps x data parallel size.\n",
      "`use_seedable_sampler` in `AcceleratorConfig` is not supported in NeuronTrainer and will be ignored.\n",
      "Pipeline parallelsim: forcing the dataloader to drop the last incomplete batch because it can cause failure if the last batch size is not divisible by the number of microbatches for the pipeline.\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 3\n",
      "  Data Parallel Size: 1\n",
      "  Tensor Parallel Size: 2\n",
      "  Pipeline Parallel Size: 1\n",
      "  Instantaneous batch size per data parallel rank = 1\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Total optimization steps = 21\n",
      "  Num trainable parameters = 596,049,920\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]The following columns in the Training set don't have a corresponding argument in `Qwen3ForCausalLM.forward` and have been ignored: teacher_logits. If teacher_logits are not expected by `Qwen3ForCausalLM.forward`,  you can safely ignore this message.\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "\n",
      "  5%|▍         | 1/21 [25:13<8:24:37, 1513.90s/it]/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "\n",
      "                                                  \n",
      "\n",
      "  5%|▍         | 1/21 [26:53<8:24:37, 1513.90s/it]\n",
      " 10%|▉         | 2/21 [26:56<3:36:27, 683.57s/it] /home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "\n",
      "                                                 \n",
      "\n",
      " 10%|▉         | 2/21 [30:01<3:36:27, 683.57s/it]\n",
      " 14%|█▍        | 3/21 [30:03<2:17:05, 456.95s/it]\n",
      "                                                 \n",
      "\n",
      " 14%|█▍        | 3/21 [30:16<2:17:05, 456.95s/it]\n",
      " 19%|█▉        | 4/21 [30:19<1:20:05, 282.68s/it]\n",
      "                                                 \n",
      "\n",
      " 19%|█▉        | 4/21 [30:31<1:20:05, 282.68s/it]\n",
      " 24%|██▍       | 5/21 [30:34<49:42, 186.40s/it]  \n",
      "                                               \n",
      "\n",
      " 24%|██▍       | 5/21 [30:47<49:42, 186.40s/it]\n",
      " 29%|██▊       | 6/21 [30:50<32:07, 128.49s/it]\n",
      "                                               \n",
      "\n",
      " 29%|██▊       | 6/21 [30:54<32:07, 128.49s/it]\n",
      " 33%|███▎      | 7/21 [30:55<20:30, 87.88s/it] \n",
      "                                              \n",
      "\n",
      " 33%|███▎      | 7/21 [30:55<20:30, 87.88s/it]\n",
      " 38%|███▊      | 8/21 [31:10<14:04, 64.92s/it]\n",
      "                                              \n",
      "\n",
      " 38%|███▊      | 8/21 [31:23<14:04, 64.92s/it]\n",
      " 43%|████▎     | 9/21 [31:26<09:55, 49.60s/it]\n",
      "                                              \n",
      "\n",
      " 43%|████▎     | 9/21 [31:39<09:55, 49.60s/it]\n",
      " 48%|████▊     | 10/21 [31:42<07:10, 39.17s/it]\n",
      "                                               \n",
      "\n",
      " 48%|████▊     | 10/21 [31:55<07:10, 39.17s/it]\n",
      " 52%|█████▏    | 11/21 [31:58<05:20, 32.05s/it]\n",
      "                                               \n",
      "\n",
      " 52%|█████▏    | 11/21 [32:11<05:20, 32.05s/it]\n",
      " 57%|█████▋    | 12/21 [32:14<04:04, 27.15s/it]\n",
      "                                               \n",
      "\n",
      " 57%|█████▋    | 12/21 [32:27<04:04, 27.15s/it]\n",
      " 62%|██████▏   | 13/21 [32:30<03:09, 23.70s/it]\n",
      "                                               \n",
      "\n",
      " 62%|██████▏   | 13/21 [32:33<03:09, 23.70s/it]\n",
      " 67%|██████▋   | 14/21 [32:34<02:04, 17.81s/it]\n",
      "                                               \n",
      "\n",
      " 67%|██████▋   | 14/21 [32:34<02:04, 17.81s/it]\n",
      " 71%|███████▏  | 15/21 [32:50<01:43, 17.24s/it]\n",
      "                                               \n",
      "\n",
      " 71%|███████▏  | 15/21 [33:03<01:43, 17.24s/it]\n",
      " 76%|███████▌  | 16/21 [33:06<01:24, 16.82s/it]\n",
      "                                               \n",
      "\n",
      " 76%|███████▌  | 16/21 [33:19<01:24, 16.82s/it]\n",
      " 81%|████████  | 17/21 [33:21<01:06, 16.52s/it]\n",
      "                                               \n",
      "\n",
      " 81%|████████  | 17/21 [33:35<01:06, 16.52s/it]\n",
      " 86%|████████▌ | 18/21 [33:37<00:48, 16.31s/it]\n",
      "                                               \n",
      "\n",
      " 86%|████████▌ | 18/21 [33:51<00:48, 16.31s/it]\n",
      " 90%|█████████ | 19/21 [33:53<00:32, 16.17s/it]\n",
      "                                               \n",
      "\n",
      " 90%|█████████ | 19/21 [34:06<00:32, 16.17s/it]\n",
      " 95%|█████████▌| 20/21 [34:09<00:16, 16.09s/it]\n",
      "                                               \n",
      "\n",
      " 95%|█████████▌| 20/21 [34:13<00:16, 16.09s/it]\n",
      "100%|██████████| 21/21 [34:13<00:00, 12.53s/it]\n",
      "                                               \n",
      "\n",
      "100%|██████████| 21/21 [34:14<00:00, 12.53s/it]Saving model checkpoint to Qwen3-0.6B-finetuned/checkpoint-21\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 21/21 [34:17<00:00, 97.96s/it]\n",
      "Saving model checkpoint to ./final_distilled_model\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "nrtucode: internal error: 54 object(s) leaked, improper teardown\n",
      "nrtucode: internal error: 54 object(s) leaked, improper teardown\n",
      "\n",
      "\n",
      "Return code: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Build the torchrun command\n",
    "cmd = [\n",
    "    \"torchrun\",\n",
    "    \"--nproc_per_node\", str(PROCESSES_PER_NODE),\n",
    "    \"src/distill_neuron_torchrun.py\",\n",
    "    \"--model_id\", MODEL_NAME,\n",
    "    \"--num_train_epochs\", str(NUM_EPOCHS),\n",
    "    \"--do_train\",\n",
    "    \"--max_steps\", str(MAX_STEPS),\n",
    "    \"--per_device_train_batch_size\", str(BS),\n",
    "    \"--gradient_accumulation_steps\", str(GRADIENT_ACCUMULATION_STEPS),\n",
    "    \"--learning_rate\", \"1e-4\",\n",
    "    \"--bf16\",\n",
    "    \"--zero_1\", \"False\",\n",
    "    \"--tensor_parallel_size\", str(TP_DEGREE),\n",
    "    \"--warmup_steps\", \"5\",\n",
    "    \"--pipeline_parallel_size\", \"1\",\n",
    "    \"--logging_steps\", str(LOGGING_STEPS),\n",
    "    \"--output_dir\", OUTPUT_DIR,\n",
    "    \"--overwrite_output_dir\"\n",
    "]\n",
    "\n",
    "print(\"Running command:\")\n",
    "print(\" \".join(cmd))\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(\"STDOUT:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"\\nSTDERR:\")\n",
    "    print(result.stderr)\n",
    "print(f\"\\nReturn code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate the shards\n",
    "\n",
    "The distilled model is saved as part of the script as a sharded checkpoint, where each model parallel worker is resposible for saving its shard of the model weights. In order to use the model for inference, we need to consolidate the model shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:70: UserWarning: Warning: Failed to import blockwise_mm_baseline_shard_n_k1_while_2loops: No module named 'neuronxcc.nki._private_kernels.blockwise_matmul_while'\n",
      "  warnings.warn(f\"Warning: {error}\")\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "Consolidating checkpoints from Qwen3-0.6B-finetuned to the safetensors format...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/bin/optimum-cli\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/optimum/commands/optimum_cli.py\", line 208, in main\n",
      "    service.run()\n",
      "  File \"/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/optimum/commands/neuron/subcommands.py\", line 65, in run\n",
      "    consolidate_model_parallel_checkpoints_to_unified_checkpoint(\n",
      "  File \"/home/ubuntu/neuron-distillation-sample/aws_neuron_venv_pytorch/lib/python3.10/site-packages/optimum/neuron/models/training/checkpointing.py\", line 183, in consolidate_model_parallel_checkpoints_to_unified_checkpoint\n",
      "    raise ValueError(f\"Could not find the tensor parallel shards from {checkpoint_dir}\")\n",
      "ValueError: Could not find the tensor parallel shards from Qwen3-0.6B-finetuned\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli neuron consolidate Qwen3-0.6B-finetuned Qwen3-0.6B-consolidated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results and Next Steps\n",
    "\n",
    "Congratulations on completing the knowledge distillation training!\n",
    "\n",
    "**What You've Accomplished:**\n",
    "\n",
    "1. ✅ Trained a 0.6B parameter student model using knowledge from a 30B parameter teacher\n",
    "2. ✅ Achieved 50x model size reduction while retaining much of the teacher's performance\n",
    "3. ✅ Learned to use distributed training on AWS Trainium with Neuron SDK\n",
    "4. ✅ Implemented custom knowledge distillation loss combining soft and hard targets\n",
    "\n",
    "**Model Outputs:**\n",
    "\n",
    "Your trained model is saved in two locations:\n",
    "- **Checkpoints**: `{OUTPUT_DIR}/` - Contains intermediate training checkpoints\n",
    "- **Final Model**: `./final_distilled_model/` - The completed distilled model ready for deployment\n",
    "\n",
    "**Evaluating Your Model:**\n",
    "\n",
    "To test your distilled model's performance:\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the distilled model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./final_distilled_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./final_distilled_model\")\n",
    "\n",
    "# Test on a sample\n",
    "test_text = \"This phone's battery life is absolutely amazing!\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "```\n",
    "\n",
    "**Expected Benefits of Distillation:**\n",
    "\n",
    "The student model (0.6B parameters) is approximately 50x smaller than the teacher model (30B parameters), which typically translates to:\n",
    "- **Reduced Model Size**: Significantly smaller memory footprint for deployment\n",
    "- **Faster Inference**: Fewer parameters mean faster forward passes\n",
    "- **Lower Costs**: Reduced compute requirements for inference\n",
    "- **Accuracy Trade-off**: Some performance loss is expected, but distillation helps retain more capability than training from scratch\n",
    "\n",
    "**Note:** Actual performance metrics will depend on your specific dataset, training configuration, and evaluation criteria. We recommend benchmarking your distilled model against the teacher on your test set to quantify the accuracy/efficiency trade-off.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. **Deploy for Inference**: Use the distilled model with AWS Inferentia for cost-effective production inference\n",
    "2. **Fine-tune Further**: Continue training on domain-specific data to improve performance\n",
    "3. **Experiment with Hyperparameters**:\n",
    "   - Try different temperature values (2.0-10.0)\n",
    "   - Adjust alpha to balance soft vs. hard loss\n",
    "   - Increase training epochs for better convergence\n",
    "4. **Quantization**: Apply INT8 quantization for additional 4x size reduction\n",
    "5. **Benchmark**: Compare inference latency and accuracy against the teacher model\n",
    "\n",
    "**Troubleshooting:**\n",
    "\n",
    "If training failed or results are poor:\n",
    "- Check that `data/output1.json` contains valid teacher logits from Lab 0\n",
    "- Verify sufficient disk space for compilation artifacts (~30GB)\n",
    "- Review CloudWatch logs for detailed error messages\n",
    "- Try reducing batch size or sequence length if running out of memory\n",
    "- Ensure Neuron SDK version compatibility with the model\n",
    "\n",
    "**Additional Resources:**\n",
    "\n",
    "- [AWS Neuron Documentation](https://awsdocs-neuron.readthedocs-hosted.com/)\n",
    "- [Optimum Neuron GitHub](https://github.com/huggingface/optimum-neuron)\n",
    "- [Knowledge Distillation Paper](https://arxiv.org/abs/1503.02531) (Hinton et al.)\n",
    "- [Qwen3 Model Card](https://huggingface.co/Qwen/Qwen3-0.6B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
