{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "## Copy tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer for 'Qwen/Qwen3-0.6B' saved to '/home/ubuntu/environment/ml/qwen/compiled_model'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. Specify the name of the Hugging Face model\n",
    "model_name = \"Qwen/Qwen3-0.6B\" \n",
    "\n",
    "# 2. Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 3. Define the local directory where you want to save the tokenizer\n",
    "local_directory = \"/home/ubuntu/environment/ml/qwen/compiled_model\"\n",
    "\n",
    "# 4. Save the tokenizer to the local directory\n",
    "tokenizer.save_pretrained(local_directory)\n",
    "\n",
    "print(f\"Tokenizer for '{model_name}' saved to '{local_directory}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation\n",
    "\n",
    "After completing the fine-tuning process, the next step is to compile the trained model for AWS Trainium inference using the Hugging Face Optimum Neuron toolchain.\n",
    "Neuron compilation optimizes the model graph and converts it into a Neuron Executable File Format (NEFF), enabling efficient execution on NeuronCores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:70: UserWarning: Warning: Failed to import blockwise_mm_baseline_shard_n_k1_while_2loops: No module named 'neuronxcc.nki._private_kernels.blockwise_matmul_while'\n",
      "  warnings.warn(f\"Warning: {error}\")\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:33: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "WARNING:Neuron:Ignoring the following kwargs as they are not supported by neuron: dict_keys(['subfolder', 'torch_dtype'])\n",
      "INFO:Neuron:Generating HLOs for the following models: ['context_encoding', 'token_generation']\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 1\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 1\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7329f3d0f7f0>, 'Ascending Ring PG Group')>\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0]]\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0]]\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0]]\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0]]\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0]]\n",
      "[2025-10-31 01:16:22.885: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0]]\n",
      "INFO:Neuron:Generating 1 hlos for key: context_encoding\n",
      "INFO:Neuron:Started loading module context_encoding\n",
      "INFO:Neuron:Finished loading module context_encoding in 0.1002206802368164 seconds\n",
      "INFO:Neuron:generating HLO: context_encoding, input example shape = torch.Size([1, 2048])\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:299: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs_soft_max, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:262: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=1, shape=torch.Size([1, 2048]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for context_encoding in 2.347781181335449 seconds, input example shape = torch.Size([1, 2048])\n",
      "INFO:Neuron:Generating 1 hlos for key: token_generation\n",
      "INFO:Neuron:Started loading module token_generation\n",
      "INFO:Neuron:Finished loading module token_generation in 0.09135556221008301 seconds\n",
      "INFO:Neuron:generating HLO: token_generation, input example shape = torch.Size([1, 1])\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:299: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs_soft_max, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:262: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for token_generation in 1.739989995956421 seconds, input example shape = torch.Size([1, 1])\n",
      "INFO:Neuron:Generated all HLOs in 4.321739912033081 seconds\n",
      "INFO:Neuron:Starting compilation for the priority HLO\n",
      "INFO:Neuron:'token_generation' is the priority model with bucket rank 0\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:283: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n",
      "neuronxcc-2.21.18209.0+043b1bf7/MODULE_87301aa5994aa3ec3488+ac10809c/model.done not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.21.18209.0+043b1bf7/MODULE_87301aa5994aa3ec3488+ac10809c/model.done not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.21.18209.0+043b1bf7/MODULE_87301aa5994aa3ec3488+ac10809c/model.log not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "2025-10-31 01:16:27.000923:  56624  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/nxd_model/token_generation/_tp0_bk0/model.MODULE_87301aa5994aa3ec3488+ac10809c.hlo_module.pb --output /tmp/nxd_model/token_generation/_tp0_bk0/model.MODULE_87301aa5994aa3ec3488+ac10809c.neff --target=trn2 --auto-cast=none --model-type=transformer --tensorizer-options=--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma  -O2 --lnc=2 --logfile=/tmp/nxd_model/token_generation/_tp0_bk0/log-neuron-cc.txt --enable-internal-neff-wrapper --verbose=35\n",
      "....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "INFO:Neuron:Done compilation for the priority HLO in 79.36669445037842 seconds\n",
      "INFO:Neuron:Updating the hlo module with optimized layout\n",
      "INFO:Neuron:Done optimizing weight layout for all HLOs in 6.9736738204956055 seconds\n",
      "INFO:Neuron:Starting compilation for all HLOs\n",
      "INFO:Neuron:Neuron compiler flags: --auto-cast=none --model-type=transformer --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' -O2  --lnc=2 --target trn2 --logfile=/tmp/nxd_model/context_encoding/_tp0_bk0/log-neuron-cc.txt\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:245: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n",
      "neuronxcc-2.21.18209.0+043b1bf7/MODULE_d520c8be8d8ce950a101+a32116a7/model.done not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.21.18209.0+043b1bf7/MODULE_d520c8be8d8ce950a101+a32116a7/model.done not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.21.18209.0+043b1bf7/MODULE_d520c8be8d8ce950a101+a32116a7/model.log not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "2025-10-31 01:17:54.000179:  56624  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/nxd_model/context_encoding/_tp0_bk0/model.MODULE_d520c8be8d8ce950a101+a32116a7.hlo_module.pb --output /tmp/nxd_model/context_encoding/_tp0_bk0/model.MODULE_d520c8be8d8ce950a101+a32116a7.neff --target=trn2 --auto-cast=none --model-type=transformer --tensorizer-options=--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma  -O2 --lnc=2 --logfile=/tmp/nxd_model/context_encoding/_tp0_bk0/log-neuron-cc.txt --verbose=35\n",
      "........Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "INFO:Neuron:Finished Compilation for all HLOs in 141.5979459285736 seconds\n",
      "..Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "INFO:Neuron:Done preparing weight layout transformation\n",
      "INFO:Neuron:Finished building model in 271.1505181789398 seconds\n",
      "Configuration saved in /home/ubuntu/environment/ml/qwen/compiled_model/neuron_config.json\n",
      "Model and configuration files saved in /home/ubuntu/environment/ml/qwen/compiled_model\n",
      "Configuration saved in /home/ubuntu/environment/ml/qwen/compiled_model/neuron_config.json\n",
      "INFO:Neuron:Sharding Weights for ranks: 0...0\n",
      "[2025-10-31 01:20:54.207: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 1\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 1\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7329f3d0f7f0>, 'Ascending Ring PG Group')>\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0]]\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0]]\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0]]\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0]]\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0]]\n",
      "[2025-10-31 01:20:54.208: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0]]\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/trace/trace.py:642: UserWarning: Removing redundant keys from checkpoint: []\n",
      "  warnings.warn(f\"Removing redundant keys from checkpoint: {keys_to_delete}\")\n",
      "INFO:Neuron:Done Sharding weights in 1.7758041390006838\n",
      "No tokenizer found while exporting /home/ubuntu/environment/distillation/Qwen3-0.6B-finetuned.\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export neuron \\\n",
    "  --model \"/home/ubuntu/environment/distillation/Qwen3-0.6B-finetuned\" \\\n",
    "  --task text-generation \\\n",
    "  --sequence_length 2048 \\\n",
    "  --batch_size 1 \\\n",
    "  /home/ubuntu/environment/ml/qwen/compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "We will install the Optimum Neuron vllm library.  Then, run inference using the compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron[vllm] in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: transformers~=4.55.4 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from optimum-neuron[vllm]) (4.55.4)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.31.4 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from optimum-neuron[vllm]) (0.36.0)\n",
      "Requirement already satisfied: numpy<=1.26.4,>=1.22.2 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.26.4)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from optimum-neuron[vllm]) (3.20.3)\n",
      "Collecting vllm==0.10.2 (from optimum-neuron[vllm])\n",
      "  Downloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (2.8.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (0.6.2)\n",
      "Requirement already satisfied: regex in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (2025.10.23)\n",
      "Collecting cachetools (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting sentencepiece (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Using cached sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (4.67.1)\n",
      "Collecting blake3 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading blake3-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting py-cpuinfo (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (0.21.4)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (0.116.2)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (3.12.15)\n",
      "Collecting openai>=1.99.1 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pydantic>=2.11.7 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (2.11.9)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (0.23.1)\n",
      "Requirement already satisfied: pillow in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (11.3.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer==0.11.3 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines_core==0.2.11 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading outlines_core-0.2.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting diskcache==5.6.3 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: lark==1.2.2 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (1.2.2)\n",
      "Collecting xgrammar==0.1.23 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading xgrammar-0.1.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (4.15.0)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (3.19.1)\n",
      "Collecting partial-json-parser (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (27.1.0)\n",
      "Collecting msgspec (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting einops (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.11.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading compressed_tensors-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.19.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: cloudpickle in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (3.1.1)\n",
      "Collecting watchfiles (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading watchfiles-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-json-logger in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (3.3.0)\n",
      "Requirement already satisfied: scipy in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (1.12.0)\n",
      "Collecting ninja (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting pybase64 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting cbor2 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading cbor2-5.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting setproctitle (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading setproctitle-1.3.7-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
      "Collecting openai-harmony>=0.0.3 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting numba==0.61.2 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading ray-2.51.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting torchaudio==2.8.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading torchaudio-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: torchvision==0.23.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from vllm==0.10.2->optimum-neuron[vllm]) (0.23.0)\n",
      "Collecting xformers==0.0.32.post1 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting frozendict (from compressed-tensors==0.11.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting astor (from depyf==0.19.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: dill in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from depyf==0.19.0->vllm==0.10.2->optimum-neuron[vllm]) (0.4.0)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from triton==3.4.0->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (80.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from huggingface-hub>=0.31.4->optimum-neuron[vllm]) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (0.48.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from pydantic>=2.11.7->vllm==0.10.2->optimum-neuron[vllm]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from pydantic>=2.11.7->vllm==0.10.2->optimum-neuron[vllm]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from pydantic>=2.11.7->vllm==0.10.2->optimum-neuron[vllm]) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from starlette<0.49.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (4.10.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (1.3.1)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading fastapi_cli-0.0.14-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (0.28.1)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading rignore-0.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading sentry_sdk-2.43.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: certifi in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (3.0.2)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm]) (4.25.1)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm]) (0.27.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.99.1->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.99.1->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading jiter-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting click!=8.3.0,>=7.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]>=2.48.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading cupy_cuda12x-13.6.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.10.2->optimum-neuron[vllm]) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.10.2->optimum-neuron[vllm]) (2.5.0)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (14.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm]) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading httptools-0.7.1-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading uvloop-0.22.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from aiohttp->vllm==0.10.2->optimum-neuron[vllm]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from aiohttp->vllm==0.10.2->optimum-neuron[vllm]) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from aiohttp->vllm==0.10.2->optimum-neuron[vllm]) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from aiohttp->vllm==0.10.2->optimum-neuron[vllm]) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from aiohttp->vllm==0.10.2->optimum-neuron[vllm]) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from aiohttp->vllm==0.10.2->optimum-neuron[vllm]) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from aiohttp->vllm==0.10.2->optimum-neuron[vllm]) (1.20.1)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm]) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/aws_neuronx_venv_pytorch_2_8_nxd_training/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm]) (2.23)\n",
      "Collecting soxr>=0.5.0 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2->optimum-neuron[vllm])\n",
      "  Downloading soxr-1.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Downloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl (436.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.11.0-py3-none-any.whl (179 kB)\n",
      "Downloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
      "Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m176.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines_core-0.2.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading xgrammar-0.1.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading fastapi_cli-0.0.14-py3-none-any.whl (11 kB)\n",
      "Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n",
      "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (359 kB)\n",
      "Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m239.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ray-2.51.0-cp310-cp310-manylinux2014_x86_64.whl (71.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (406 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
      "Downloading rignore-0.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.6/959.6 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.43.0-py2.py3-none-any.whl (400 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading httptools-0.7.1-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (440 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading uvloop-0.22.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m165.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (387 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading cbor2-5.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (247 kB)\n",
      "Downloading cupy_cuda12x-13.6.0-cp310-cp310-manylinux2014_x86_64.whl (112.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-1.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (68 kB)\n",
      "Using cached sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "Downloading setproctitle-1.3.7-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (31 kB)\n",
      "Installing collected packages: py-cpuinfo, fastrlock, websockets, uvloop, soxr, shellingham, setproctitle, sentry-sdk, sentencepiece, rignore, python-multipart, python-dotenv, pycountry, pybase64, partial-json-parser, outlines_core, opencv-python-headless, ninja, msgspec, msgpack, llvmlite, llguidance, jiter, interegular, httptools, gguf, frozendict, einops, dnspython, distro, diskcache, cupy-cuda12x, click, cbor2, cachetools, blake3, astor, uvicorn, tiktoken, soundfile, numba, email-validator, depyf, watchfiles, typer, rich-toolkit, pydantic-extra-types, openai-harmony, lm-format-enforcer, xformers, torchaudio, ray, prometheus-fastapi-instrumentator, openai, xgrammar, mistral_common, fastapi-cloud-cli, fastapi-cli, compressed-tensors, vllm\n",
      "\u001b[2K  Attempting uninstall: llvmlite0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/60\u001b[0m [msgpack]ython-headless]\n",
      "\u001b[2K    Found existing installation: llvmlite 0.45.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/60\u001b[0m [msgpack]\n",
      "\u001b[2K    Uninstalling llvmlite-0.45.0:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/60\u001b[0m [msgpack]\n",
      "\u001b[2K      Successfully uninstalled llvmlite-0.45.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/60\u001b[0m [msgpack]\n",
      "\u001b[2K  Attempting uninstall: click[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/60\u001b[0m [cupy-cuda12x]\n",
      "\u001b[2K    Found existing installation: click 8.3.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/60\u001b[0m [cupy-cuda12x]\n",
      "\u001b[2K    Uninstalling click-8.3.0:[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/60\u001b[0m [cupy-cuda12x]\n",
      "\u001b[2K      Successfully uninstalled click-8.3.0m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/60\u001b[0m [cupy-cuda12x]\n",
      "\u001b[2K  Attempting uninstall: numba━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/60\u001b[0m [uvicorn]]\n",
      "\u001b[2K    Found existing installation: numba 0.62.00m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/60\u001b[0m [uvicorn]\n",
      "\u001b[2K    Uninstalling numba-0.62.0:━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m40/60\u001b[0m [numba]\n",
      "\u001b[2K      Successfully uninstalled numba-0.62.0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m40/60\u001b[0m [numba]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60/60\u001b[0m [vllm]0m [vllm]0m [mistral_common]\n",
      "\u001b[1A\u001b[2KSuccessfully installed astor-0.8.1 blake3-1.0.8 cachetools-6.2.1 cbor2-5.7.1 click-8.2.1 compressed-tensors-0.11.0 cupy-cuda12x-13.6.0 depyf-0.19.0 diskcache-5.6.3 distro-1.9.0 dnspython-2.8.0 einops-0.8.1 email-validator-2.3.0 fastapi-cli-0.0.14 fastapi-cloud-cli-0.3.1 fastrlock-0.8.3 frozendict-2.4.6 gguf-0.17.1 httptools-0.7.1 interegular-0.3.3 jiter-0.11.1 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.11.3 mistral_common-1.8.5 msgpack-1.1.2 msgspec-0.19.0 ninja-1.13.0 numba-0.61.2 openai-2.6.1 openai-harmony-0.0.4 opencv-python-headless-4.11.0.86 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 py-cpuinfo-9.0.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.6 python-dotenv-1.2.1 python-multipart-0.0.20 ray-2.51.0 rich-toolkit-0.15.1 rignore-0.7.2 sentencepiece-0.2.1 sentry-sdk-2.43.0 setproctitle-1.3.7 shellingham-1.5.4 soundfile-0.13.1 soxr-1.0.0 tiktoken-0.12.0 torchaudio-2.8.0 typer-0.20.0 uvicorn-0.38.0 uvloop-0.22.1 vllm-0.10.2 watchfiles-1.1.1 websockets-15.0.1 xformers-0.0.32.post1 xgrammar-0.1.23\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q optimum-neuron[vllm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the batch inference example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-31 01:38:28 [utils.py:328] non-default args: {'max_model_len': 2048, 'tensor_parallel_size': 2, 'max_num_seqs': 1, 'disable_log_stats': True, 'model': '/home/ubuntu/environment/ml/qwen/compiled_model'}\n",
      "INFO 10-31 01:38:28 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n",
      "INFO 10-31 01:38:28 [__init__.py:1815] Using max model len 2048\n",
      "INFO 10-31 01:38:28 [llm_engine.py:221] Initializing a V0 LLM engine (v0.10.2) with config: model='/home/ubuntu/environment/ml/qwen/compiled_model', speculative_config=None, tokenizer='/home/ubuntu/environment/ml/qwen/compiled_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cpu, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/home/ubuntu/environment/ml/qwen/compiled_model, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":0,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}, use_cached_outputs=False, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Loading sharded checkpoint from /home/ubuntu/environment/ml/qwen/compiled_model/checkpoint/weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 10-31 01:38:35 [__init__.py:3804] Current vLLM config is not set.\n",
      "WARNING 10-31 01:38:35 [__init__.py:3804] Current vLLM config is not set.\n",
      "INFO 10-31 01:38:35 [executor_base.py:114] # neuron blocks: 2, # CPU blocks: 0\n",
      "INFO 10-31 01:38:35 [executor_base.py:119] Maximum concurrency for 2048 tokens per request: 2.00x\n",
      "INFO 10-31 01:38:35 [llm_engine.py:420] init engine (profile, create kv cache, warmup model) took 0.00 seconds\n",
      "INFO 10-31 01:38:35 [llm.py:295] Supported_tasks: ['generate']\n",
      "INFO 10-31 01:38:35 [__init__.py:36] No IOProcessor plugins requested by the model\n",
      "['<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a8163e517b4fc09f7a0e32af60a3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e967191fcb442bb17515dc3bdacd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!\\n</think>assistant\\nassistant\\nI deeply regret purchasing this defective product.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\n</think>assistant\\nThe battery life of this phone is absolutely amazing!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe defective product was returned as expected.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe team just won the championship - best day ever!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe staff at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\n</think>assistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe flight was delayed for the third time this week.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\n</think>assistant\\nThe battery life of this phone is absolutely amazing!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\n</think>assistant\\nThe product contains defects not fully specified.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe staff exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe flight was delayed for the third time this week.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: \"\\nThe phone's battery life is absolutely amazing!\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe store will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe team just won the championship - best day ever!\\n<tool_call>\\n adapting to the circumstances\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!。\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team just won the championship - best day ever!\\nassistant\\nassistant\\nThe team' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\n</think>assistant\\nThe staff exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe battery life of this smartphone exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe store will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe team just won the championship.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nOur flight was delayed for the third time this week.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: \"\\nassistant\\nThe phone's battery life is absolutely amazing!\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe store will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe product contains defects as specified in the service contract.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe championship - best day ever!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe repairs made last fiscal month had ended this week.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\n</think>assistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: \"\\nassistant\\nThe phone's battery life is absolutely amazing!\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe store will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: \"\\nassistant\\nThis year's championship - best day ever!\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: \"\\n</think>user\\nI can't believe how rude the staff was today.\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe flight was delayed for the third time this week.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe battery life of this phone is absolutely amazing!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\n</think>assistant\\nThe store will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe product contains parts worn by prolonged use.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\n.The fireworks fell silently into the night.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe staff exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nenses\\nThis package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe weather is 72 degrees with partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: \"\\nassistant\\nThis phone's battery life is absolutely amazing!\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe store will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe ceremony at this championship - best day ever!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe flight was delayed for the third time this week.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: \"\\nassistant\\nThe phone's battery life is absolutely amazing!\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe store will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe product contains parts that are not in good condition.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe team just won the championship - best day ever!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I can't believe how rude the staff was today.\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The weather is 72 degrees with partial clouds.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe forecast shows partial clouds.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    My flight was delayed for the third time this week.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe flight was delayed for the third time this week.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The package arrived on schedule as expected.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe package arrived on schedule as expected.' \n",
      "\n",
      "Prompt: \"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    This phone's battery life is absolutely amazing!\\n    <|im_start|>assistant\", \n",
      "\n",
      " Generated text: \"\\nassistant\\nThe phone's battery life is absolutely amazing!\" \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The store will be closed from 2PM to 4PM.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant will be closed from 2PM to 4PM.' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    I deeply regret purchasing this defective product.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe service at this restaurant exceeded all my expectations!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    Our team just won the championship - best day ever!\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe team just won the championship - best day ever!' \n",
      "\n",
      "Prompt: '<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The report contains data from the last fiscal year.\\n    <|im_start|>assistant', \n",
      "\n",
      " Generated text: '\\nassistant\\nThe report contains data from the last fiscal year.' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(\n",
    "    model=\"/home/ubuntu/environment/ml/qwen/compiled_model\", #local compiled model\n",
    "    max_num_seqs=1,\n",
    "    max_model_len=2048,\n",
    "    tensor_parallel_size=2,)\n",
    "\n",
    "def create_conversation(sample):\n",
    "    return f\"\"\"<|im_start|>system\n",
    "    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\n",
    "    <|im_start|>user\n",
    "    {sample}\n",
    "    <|im_start|>assistant\"\"\"\n",
    "\n",
    "prompts = []\n",
    "with open('/home/ubuntu/environment/distillation/data/dataset.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            prompts.append( create_conversation(line.strip()) )\n",
    "print(prompts)\n",
    "sampling_params = SamplingParams(max_tokens=2048, temperature=0.8)\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "print(\"#########################################################\")\n",
    "\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, \\n\\n Generated text: {generated_text!r} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start an inference endpoint on the current instance, like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model=\"/home/ubuntu/environment/ml/qwen/compiled_model\" \\\n",
    "    --max-num-seqs=1 \\\n",
    "    --max-model-len=2048 \\\n",
    "    --tensor-parallel-size=2 \\\n",
    "    --port=8080 \\\n",
    "    --device \"neuron\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And query the inference endpoint like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl 127.0.0.1:8080/v1/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -X POST \\\n",
    "    -d '{\"prompt\":\"<|im_start|>system\\n    You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\\n    <|im_start|>user\\n    The service at this restaurant exceeded all my expectations!\\n    <|im_start|>assistant\", \"temperature\": 0.8, \"max_tokens\":128}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuronx_venv_pytorch_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
