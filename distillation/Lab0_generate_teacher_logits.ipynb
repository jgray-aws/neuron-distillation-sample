{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Generate Teacher Logits\n",
    "\n",
    "This notebook generates teacher model logits for knowledge distillation. The teacher model (Qwen3-30B-A3B) processes a dataset and outputs logits that will be used to train a smaller student model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "Import required libraries for model inference, tokenization, and Neuron-specific configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:68: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:70: UserWarning: Warning: Failed to import blockwise_mm_baseline_shard_n_k1_while_2loops: No module named 'neuronxcc.nki._private_kernels.blockwise_matmul_while'\n",
      "  warnings.warn(f\"Warning: {error}\")\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/modules/moe/moe_fused_tkg.py:48: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/attention/utils.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.modules.custom_calls import neuron_cumsum\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_model.py:12: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.modules.attention.gqa import GQA, GroupQueryAttention_QKV\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_model.py:12: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.modules.attention.gqa import GQA, GroupQueryAttention_QKV\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/lora_serving/lora_model.py:12: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.modules.attention.gqa import GQA, GroupQueryAttention_QKV\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/qwen3_moe/modeling_qwen3_moe.py:41: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/qwen3_moe/modeling_qwen3_moe.py:41: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/qwen3_moe/modeling_qwen3_moe.py:41: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.modules.attention.attention_base import NeuronAttentionBase\n",
      "/tmp/ipykernel_3258171/3916892705.py:7: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed_inference.models.qwen3_moe.modeling_qwen3_moe import Qwen3MoeInferenceConfig, NeuronQwen3MoeForCausalLM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x754d77fc3cd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from transformers import AutoTokenizer, GenerationConfig\n",
    "from neuronx_distributed_inference.models.config import MoENeuronConfig, OnDeviceSamplingConfig\n",
    "from neuronx_distributed_inference.models.qwen3_moe.modeling_qwen3_moe import Qwen3MoeInferenceConfig, NeuronQwen3MoeForCausalLM\n",
    "from neuronx_distributed_inference.utils.hf_adapter import HuggingFaceGenerationAdapter, load_pretrained_config\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set model paths and file locations. The teacher model will be compiled and saved to the traced model path for efficient inference on AWS Neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"Qwen/Qwen3-30B-A3B\"\n",
    "traced_model_path = \"/home/ubuntu/traced_model/Qwen3-30B-A3B/\"\n",
    "dataset_file = \"data/dataset.txt\"\n",
    "output_file = \"output.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Conversation Template\n",
    "\n",
    "Define a function to format input text as a conversation for the sentiment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversation(sample):\n",
    "    system_message = (\n",
    "        \"You are a sentiment classifier. You take input strings and return the sentiment of POSITIVE, NEGATIVE, or NEUTRAL. Only return the sentiment.\"\n",
    "    )\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": sample\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model Configuration\n",
    "\n",
    "Configure the Neuron-specific settings for the Qwen3 MoE model:\n",
    "- Tensor parallelism degree: 8 (distributes model across 8 NeuronCores)\n",
    "- Enable logit output for distillation\n",
    "- Set sampling parameters for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:NeuronConfig init: Unexpected keyword arguments: {'output_scores': True}\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig.from_pretrained(model_path)\n",
    "\n",
    "neuron_config = MoENeuronConfig(\n",
    "    tp_degree=8,\n",
    "    batch_size=1,\n",
    "    max_context_length=128,\n",
    "    seq_len=1024,\n",
    "    on_device_sampling_config=OnDeviceSamplingConfig(do_sample=True, temperature=0.6, top_k=20, top_p=0.95),\n",
    "    enable_bucketing=False,\n",
    "    flash_decoding_enabled=False,\n",
    "    output_scores=True,\n",
    "    output_logits=True\n",
    ")\n",
    "\n",
    "config = Qwen3MoeInferenceConfig(\n",
    "    neuron_config,\n",
    "    load_config=load_pretrained_config(model_path),\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, padding_side=\"right\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Save Model\n",
    "\n",
    "Compile the model for AWS Neuron hardware. This step converts the model to a Neuron-optimized format and saves it for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Saving the neuron_config to /home/ubuntu/traced_model/Qwen3-30B-A3B/\n",
      "INFO:Neuron:Generating HLOs for the following models: ['context_encoding_model', 'token_generation_model']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling and saving model...\n",
      "[2025-10-23 18:41:51.532: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 8\n",
      "[2025-10-23 18:41:51.533: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1\n",
      "[2025-10-23 18:41:51.534: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1\n",
      "[2025-10-23 18:41:51.535: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1\n",
      "[2025-10-23 18:41:51.536: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 8\n",
      "[2025-10-23 18:41:51.536: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x754b1f3b9cf0>, 'Ascending Ring PG Group')>\n",
      "[2025-10-23 18:41:51.537: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "[2025-10-23 18:41:51.538: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:41:51.538: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:41:51.538: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:41:51.539: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:41:51.539: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Generating 1 hlos for key: context_encoding_model\n",
      "INFO:Neuron:Started loading module context_encoding_model\n",
      "INFO:Neuron:Finished loading module context_encoding_model in 0.6785175800323486 seconds\n",
      "INFO:Neuron:generating HLO: context_encoding_model, input example shape = torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-23 18:41:55.678: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.760: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.772: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.783: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.795: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.807: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.818: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.830: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.841: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.852: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.863: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch/autograd/function.py:575: DeprecationWarning: Block dimension is deprecated. The leading dimension of SBUF tensor must be partition dimension\n",
      "  return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-23 18:41:55.877: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.888: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.899: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.910: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.920: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.932: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.943: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.954: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.965: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.977: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:55.988: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.000: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.011: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.022: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.038: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.049: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.060: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.072: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.084: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.095: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.106: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.117: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.127: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.138: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.148: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.160: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.171: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.183: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.194: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.206: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.217: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.228: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.242: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.254: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.266: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.277: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n",
      "[2025-10-23 18:41:56.287: W neuronx_distributed/modules/moe/expert_mlps_v2.py:765] T 128 not divisible by block_size 512, cannot use index calc kernel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=1, shape=torch.Size([1, 128]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for context_encoding_model in 10.564492225646973 seconds, input example shape = torch.Size([1, 128])\n",
      "INFO:Neuron:Generating 1 hlos for key: token_generation_model\n",
      "INFO:Neuron:Started loading module token_generation_model\n",
      "INFO:Neuron:Finished loading module token_generation_model in 0.6945993900299072 seconds\n",
      "INFO:Neuron:generating HLO: token_generation_model, input example shape = torch.Size([1, 1])\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:507: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:374: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/modules/generation/sampling.py:327: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.neuron_config.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=5, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=6, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for token_generation_model in 8.787945032119751 seconds, input example shape = torch.Size([1, 1])\n",
      "INFO:Neuron:Generated all HLOs in 21.071417570114136 seconds\n",
      "INFO:Neuron:Removing 96 kernel weights from the frontend attributes\n",
      "INFO:Neuron:Starting compilation for the priority HLO\n",
      "INFO:Neuron:'token_generation_model' is the priority model with bucket rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:42:13.000145:  3258171  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_de61ac37b4eeddad6841+9006d3c6/model.neff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:283: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n",
      "INFO:Neuron:Done compilation for the priority HLO in 0.5761313438415527 seconds\n",
      "INFO:Neuron:Updating the hlo module with optimized layout\n",
      "INFO:Neuron:Done optimizing weight layout for all HLOs in 1.306518793106079 seconds\n",
      "INFO:Neuron:Starting compilation for all HLOs\n",
      "INFO:Neuron:Neuron compiler flags: --enable-saturate-infinity --enable-mixed-precision-accumulation --model-type transformer -O1 --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2' --auto-cast=none --internal-enable-dge-levels vector_dynamic_offsets --internal-hlo2tensorizer-options='--verify-hlo=true' --internal-hlo2tensorizer-options='--verify-hlo=true'  --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk0/log-neuron-cc.txt\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:245: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:42:15.000868:  3258171  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.21.18209.0+043b1bf7/MODULE_9e722d575a2b2a33625f+2667e3c1/model.neff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Finished Compilation for all HLOs in 1.5379798412322998 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Done preparing weight layout transformation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Finished building model in 55.69548773765564 seconds\n",
      "INFO:Neuron:SKIPPING pre-sharding the checkpoints. The checkpoints will be sharded during load time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/ubuntu/traced_model/Qwen3-30B-A3B/tokenizer_config.json',\n",
       " '/home/ubuntu/traced_model/Qwen3-30B-A3B/special_tokens_map.json',\n",
       " '/home/ubuntu/traced_model/Qwen3-30B-A3B/chat_template.jinja',\n",
       " '/home/ubuntu/traced_model/Qwen3-30B-A3B/vocab.json',\n",
       " '/home/ubuntu/traced_model/Qwen3-30B-A3B/merges.txt',\n",
       " '/home/ubuntu/traced_model/Qwen3-30B-A3B/added_tokens.json',\n",
       " '/home/ubuntu/traced_model/Qwen3-30B-A3B/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nCompiling and saving model...\")\n",
    "model = NeuronQwen3MoeForCausalLM(model_path, config)\n",
    "model.compile(traced_model_path)\n",
    "tokenizer.save_pretrained(traced_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Compiled Model\n",
    "\n",
    "Load the compiled model from disk for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:NeuronConfig init: Unexpected keyword arguments: {'apply_seq_ids_mask': False, 'enable_long_context_mode': False, 'enable_output_completion_notifications': False, 'enable_token_tree': False, 'is_chunked_prefill': False, 'is_prefill_stage': None, 'kv_cache_tiling': False, 'normalize_top_k_affinities': True, 'scratchpad_page_size': None, 'skip_warmup': False, 'tile_cc': False, 'weights_to_skip_layout_optimization': []}\n",
      "INFO:Neuron:Sharding weights on load...\n",
      "INFO:Neuron:Sharding Weights for ranks: 0...7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-23 18:43:14.892: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing tensor model parallel with size 8\n",
      "[2025-10-23 18:43:14.893: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing pipeline model parallel with size 1\n",
      "[2025-10-23 18:43:14.894: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing context model parallel with size 1\n",
      "[2025-10-23 18:43:14.895: I neuronx_distributed/parallel_layers/parallel_state.py:633] > initializing data parallel with size 1\n",
      "[2025-10-23 18:43:14.896: I neuronx_distributed/parallel_layers/parallel_state.py:634] > initializing world size to 8\n",
      "[2025-10-23 18:43:14.897: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x754b1f3b9cf0>, 'Ascending Ring PG Group')>\n",
      "[2025-10-23 18:43:14.899: I neuronx_distributed/parallel_layers/parallel_state.py:658] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "[2025-10-23 18:43:14.899: I neuronx_distributed/parallel_layers/parallel_state.py:659] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:43:14.900: I neuronx_distributed/parallel_layers/parallel_state.py:660] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:43:14.901: I neuronx_distributed/parallel_layers/parallel_state.py:661] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:43:14.901: I neuronx_distributed/parallel_layers/parallel_state.py:662] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n",
      "[2025-10-23 18:43:14.901: I neuronx_distributed/parallel_layers/parallel_state.py:663] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7511161ec1ea4719ac30735f965c65ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: lm_head.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: embed_tokens.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.self_attn.q_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.self_attn.k_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.self_attn.v_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.self_attn.o_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.input_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.post_attention_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: norm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.0.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.1.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.2.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.3.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.4.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.5.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.6.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.7.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.8.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.9.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.10.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.11.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.12.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.13.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.14.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.15.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.16.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.17.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.18.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.19.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.20.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.21.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.22.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.23.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.24.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.25.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.26.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.27.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.28.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.29.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.30.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.31.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.32.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.33.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.34.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.35.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.36.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.37.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.38.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.39.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.40.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.41.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.42.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.43.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.44.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.45.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.46.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.self_attn.k_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.self_attn.q_layernorm.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.mlp.router.linear_router.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.mlp.expert_mlps.mlp_op.gate_up_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed_inference/models/application_base.py:552: UserWarning: Found torch.float32 weights in checkpoint: layers.47.mlp.expert_mlps.mlp_op.down_proj.weight. Will convert to torch.bfloat16\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_2_7/lib/python3.10/site-packages/neuronx_distributed/trace/trace.py:642: UserWarning: Removing redundant keys from checkpoint: ['layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.v_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.32.self_attn.q_proj.weight', 'layers.32.self_attn.k_proj.weight', 'layers.32.self_attn.v_proj.weight', 'layers.32.self_attn.o_proj.weight', 'layers.33.self_attn.q_proj.weight', 'layers.33.self_attn.k_proj.weight', 'layers.33.self_attn.v_proj.weight', 'layers.33.self_attn.o_proj.weight', 'layers.34.self_attn.q_proj.weight', 'layers.34.self_attn.k_proj.weight', 'layers.34.self_attn.v_proj.weight', 'layers.34.self_attn.o_proj.weight', 'layers.35.self_attn.q_proj.weight', 'layers.35.self_attn.k_proj.weight', 'layers.35.self_attn.v_proj.weight', 'layers.35.self_attn.o_proj.weight', 'layers.36.self_attn.q_proj.weight', 'layers.36.self_attn.k_proj.weight', 'layers.36.self_attn.v_proj.weight', 'layers.36.self_attn.o_proj.weight', 'layers.37.self_attn.q_proj.weight', 'layers.37.self_attn.k_proj.weight', 'layers.37.self_attn.v_proj.weight', 'layers.37.self_attn.o_proj.weight', 'layers.38.self_attn.q_proj.weight', 'layers.38.self_attn.k_proj.weight', 'layers.38.self_attn.v_proj.weight', 'layers.38.self_attn.o_proj.weight', 'layers.39.self_attn.q_proj.weight', 'layers.39.self_attn.k_proj.weight', 'layers.39.self_attn.v_proj.weight', 'layers.39.self_attn.o_proj.weight', 'layers.40.self_attn.q_proj.weight', 'layers.40.self_attn.k_proj.weight', 'layers.40.self_attn.v_proj.weight', 'layers.40.self_attn.o_proj.weight', 'layers.41.self_attn.q_proj.weight', 'layers.41.self_attn.k_proj.weight', 'layers.41.self_attn.v_proj.weight', 'layers.41.self_attn.o_proj.weight', 'layers.42.self_attn.q_proj.weight', 'layers.42.self_attn.k_proj.weight', 'layers.42.self_attn.v_proj.weight', 'layers.42.self_attn.o_proj.weight', 'layers.43.self_attn.q_proj.weight', 'layers.43.self_attn.k_proj.weight', 'layers.43.self_attn.v_proj.weight', 'layers.43.self_attn.o_proj.weight', 'layers.44.self_attn.q_proj.weight', 'layers.44.self_attn.k_proj.weight', 'layers.44.self_attn.v_proj.weight', 'layers.44.self_attn.o_proj.weight', 'layers.45.self_attn.q_proj.weight', 'layers.45.self_attn.k_proj.weight', 'layers.45.self_attn.v_proj.weight', 'layers.45.self_attn.o_proj.weight', 'layers.46.self_attn.q_proj.weight', 'layers.46.self_attn.k_proj.weight', 'layers.46.self_attn.v_proj.weight', 'layers.46.self_attn.o_proj.weight', 'layers.47.self_attn.q_proj.weight', 'layers.47.self_attn.k_proj.weight', 'layers.47.self_attn.v_proj.weight', 'layers.47.self_attn.o_proj.weight', 'layers.0.mlp.expert_mlps.spmd_rank.rank', 'layers.1.mlp.expert_mlps.spmd_rank.rank', 'layers.2.mlp.expert_mlps.spmd_rank.rank', 'layers.3.mlp.expert_mlps.spmd_rank.rank', 'layers.4.mlp.expert_mlps.spmd_rank.rank', 'layers.5.mlp.expert_mlps.spmd_rank.rank', 'layers.6.mlp.expert_mlps.spmd_rank.rank', 'layers.7.mlp.expert_mlps.spmd_rank.rank', 'layers.8.mlp.expert_mlps.spmd_rank.rank', 'layers.9.mlp.expert_mlps.spmd_rank.rank', 'layers.10.mlp.expert_mlps.spmd_rank.rank', 'layers.11.mlp.expert_mlps.spmd_rank.rank', 'layers.12.mlp.expert_mlps.spmd_rank.rank', 'layers.13.mlp.expert_mlps.spmd_rank.rank', 'layers.14.mlp.expert_mlps.spmd_rank.rank', 'layers.15.mlp.expert_mlps.spmd_rank.rank', 'layers.16.mlp.expert_mlps.spmd_rank.rank', 'layers.17.mlp.expert_mlps.spmd_rank.rank', 'layers.18.mlp.expert_mlps.spmd_rank.rank', 'layers.19.mlp.expert_mlps.spmd_rank.rank', 'layers.20.mlp.expert_mlps.spmd_rank.rank', 'layers.21.mlp.expert_mlps.spmd_rank.rank', 'layers.22.mlp.expert_mlps.spmd_rank.rank', 'layers.23.mlp.expert_mlps.spmd_rank.rank', 'layers.24.mlp.expert_mlps.spmd_rank.rank', 'layers.25.mlp.expert_mlps.spmd_rank.rank', 'layers.26.mlp.expert_mlps.spmd_rank.rank', 'layers.27.mlp.expert_mlps.spmd_rank.rank', 'layers.28.mlp.expert_mlps.spmd_rank.rank', 'layers.29.mlp.expert_mlps.spmd_rank.rank', 'layers.30.mlp.expert_mlps.spmd_rank.rank', 'layers.31.mlp.expert_mlps.spmd_rank.rank', 'layers.32.mlp.expert_mlps.spmd_rank.rank', 'layers.33.mlp.expert_mlps.spmd_rank.rank', 'layers.34.mlp.expert_mlps.spmd_rank.rank', 'layers.35.mlp.expert_mlps.spmd_rank.rank', 'layers.36.mlp.expert_mlps.spmd_rank.rank', 'layers.37.mlp.expert_mlps.spmd_rank.rank', 'layers.38.mlp.expert_mlps.spmd_rank.rank', 'layers.39.mlp.expert_mlps.spmd_rank.rank', 'layers.40.mlp.expert_mlps.spmd_rank.rank', 'layers.41.mlp.expert_mlps.spmd_rank.rank', 'layers.42.mlp.expert_mlps.spmd_rank.rank', 'layers.43.mlp.expert_mlps.spmd_rank.rank', 'layers.44.mlp.expert_mlps.spmd_rank.rank', 'layers.45.mlp.expert_mlps.spmd_rank.rank', 'layers.46.mlp.expert_mlps.spmd_rank.rank', 'layers.47.mlp.expert_mlps.spmd_rank.rank']\n",
      "  warnings.warn(f\"Removing redundant keys from checkpoint: {keys_to_delete}\")\n",
      "INFO:Neuron:Done Sharding weights in 72.05030099023134\n",
      "INFO:Neuron:Finished weights loading in 94.67891277838498 seconds\n",
      "INFO:Neuron:Warming up the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-Oct-23 18:44:49.0575 3258171:3259075 [6] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):213 CCOM WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "2025-Oct-23 18:44:49.0585 3258171:3259075 [6] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Oct-23 18:44:49.0595 3258171:3259075 [6] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Oct-23 18:44:49.0605 3258171:3259075 [6] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Warmup completed in 0.6640217304229736 seconds.\n"
     ]
    }
   ],
   "source": [
    "model = NeuronQwen3MoeForCausalLM(traced_model_path)\n",
    "model.load(traced_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(traced_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Dataset and Generate Logits\n",
    "\n",
    "Process each line in the dataset through the teacher model:\n",
    "1. Format input as a conversation\n",
    "2. Generate output with logits\n",
    "3. Extract finite logits (filter out -inf values)\n",
    "4. Save results with prompt, generated text, and token logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "HuggingFaceGenerationAdapter has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The service at this restaurant exceeded all my exp...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I can't believe how rude the staff was today.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The weather is 72 degrees with partial clouds.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: My flight was delayed for the third time this week...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The package arrived on schedule as expected.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: This phone's battery life is absolutely amazing!\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The store will be closed from 2PM to 4PM.\n",
      "...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: I deeply regret purchasing this defective product....\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: Our team just won the championship - best day ever...\n",
      "Error message: 'super' object has no attribute 'generate'\n",
      "Error processing prompt: The report contains data from the last fiscal year...\n",
      "Error message: 'super' object has no attribute 'generate'\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with open(dataset_file, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            try:\n",
    "                input_text = create_conversation(line.strip())\n",
    "                formatted_chat = tokenizer.apply_chat_template(\n",
    "                    input_text,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True,\n",
    "                    enable_thinking=False\n",
    "                )\n",
    "                inputs = tokenizer(formatted_chat, padding=True, return_tensors=\"pt\")\n",
    "                generation_model = HuggingFaceGenerationAdapter(model)\n",
    "                outputs = generation_model.generate(\n",
    "                    inputs.input_ids,\n",
    "                    generation_config=generation_config,\n",
    "                    attention_mask=inputs.attention_mask,\n",
    "                    max_length=model.config.neuron_config.max_length,\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_scores=True,\n",
    "                    output_logits=True\n",
    "                )\n",
    "                \n",
    "                print(outputs)\n",
    "                generated_tokens = outputs.sequences[0]\n",
    "                token_logits = outputs.scores\n",
    "                generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "                print(generated_text)\n",
    "                \n",
    "                token_logits_list = []\n",
    "                for logits in token_logits:\n",
    "                    finite_mask = torch.isfinite(logits[0])\n",
    "                    finite_indices = torch.nonzero(finite_mask).squeeze().tolist()\n",
    "                    finite_logits = logits[0][finite_mask]\n",
    "                    token_info = {\n",
    "                        'indices': finite_indices,\n",
    "                        'logits': finite_logits.tolist()\n",
    "                    }\n",
    "                    token_logits_list.append(token_info)\n",
    "                \n",
    "                print(token_logits_list)\n",
    "                results.append({\n",
    "                    'prompt': line.strip(),\n",
    "                    'response': {\n",
    "                        'generated_text': generated_text,\n",
    "                        'token_logits': token_logits_list\n",
    "                    }\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing prompt: {line[:50]}...\")\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                results.append({\n",
    "                    'prompt': line.strip(),\n",
    "                    'error': str(e)\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Write the generated logits and responses to a JSON file for use in distillation training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Processing complete! Processed {len(results)} prompts. Results written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuronx_venv_pytorch_2_7",
   "language": "python",
   "name": "aws_neuronx_venv_pytorch_2_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
